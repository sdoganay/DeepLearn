{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seda Nur DoÄŸanay - S004299 - Computer Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside input10.py, you can see that L2 Regularization is inserted for avoiding over-fitting.\n",
    "\n",
    "Also in config.py, you can see how the total number of hidden parameters are calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_network2():\n",
    "    \n",
    "    config.train_dir = '/tmp/cifar10_train_network2'\n",
    "    config.eval_dir = '/tmp/cifar10_eval_network2'\n",
    "    config.data_path= '/tmp/cifar10_data'\n",
    "    config.batch_size = 128\n",
    "\n",
    "    #set the parameters for network_1\n",
    "    config.conv1_w_shape = [5, 5, 3, 32]\n",
    "    config.conv1_b_shape = [config.conv1_w_shape[3]]\n",
    "    config.conv1_b = 0.0\n",
    "\n",
    "    # norm1\n",
    "\n",
    "    config.pool1_ksize_shape = [1, 4, 4, 1]\n",
    "    config.pool1_stride_shape = [1, 2, 2, 1]\n",
    "\n",
    "    config.conv2_w_shape = [5, 5, config.conv1_w_shape[3], 32]\n",
    "    config.conv2_b_shape = [config.conv2_w_shape[3]]\n",
    "    config.conv2_b = 0.1\n",
    "\n",
    "    # norm2\n",
    "\n",
    "    config.pool2_ksize_shape = [1, 4, 4, 1]\n",
    "    config.pool2_stride_shape = [1, 2, 2, 1]\n",
    "\n",
    "    config.local3_w_dim = 192\n",
    "    config.local3_w_shape = []  # not directly in my control\n",
    "    config.local3_b_shape = [config.local3_w_dim]\n",
    "    config.local3_b = 0.1\n",
    "\n",
    "    config.local4_w_shape = [config.local3_w_dim, 192/2]\n",
    "    config.local4_b_shape = [config.local4_w_shape[1]]\n",
    "    config.local4_b = 0.1\n",
    "\n",
    "    config.softmax_w_shape = [config.local4_w_shape[1], config.NUM_CLASSES]\n",
    "    config.softmax_b_shape = [config.NUM_CLASSES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initialize_network2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    print(\"network_2 training starts...\")\n",
    "    import cifar10_train\n",
    "    cifar10_train.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    print(\"network_2 evaluating starts...\")\n",
    "    import cifar10_eval\n",
    "    cifar10_eval.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network_2 training starts...\n",
      "Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\n",
      "TRAIN - images shape:  (128, 24, 24, 3) labels shape:  (128,)\n",
      "TRAIN - image e.g. Tensor(\"strided_slice_1:0\", shape=(24, 24, 3), dtype=float32)\n",
      "TRAIN - label e.g. Tensor(\"strided_slice_2:0\", shape=(), dtype=int32)\n",
      "dim 1152\n",
      "actual_shape [1152, 192]\n",
      "# of hidden parameters 268938  <= 500000\n",
      "INFO:tensorflow:Summary name conv1/weight_loss (raw) is illegal; using conv1/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name conv2/weight_loss (raw) is illegal; using conv2/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name local3/weight_loss (raw) is illegal; using local3/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name local4/weight_loss (raw) is illegal; using local4/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name softmax_linear/weight_loss (raw) is illegal; using softmax_linear/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name cross_entropy (raw) is illegal; using cross_entropy__raw_ instead.\n",
      "INFO:tensorflow:Summary name total_loss (raw) is illegal; using total_loss__raw_ instead.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/cifar10_train_network2/model.ckpt.\n",
      "2017-05-06 22:48:17.692628: step 0, loss = 2.89 (107.7 examples/sec; 1.188 sec/batch)\n",
      "2017-05-06 22:48:22.806283: step 10, loss = 2.89 (250.3 examples/sec; 0.511 sec/batch)\n",
      "2017-05-06 22:48:28.464370: step 20, loss = 2.88 (226.2 examples/sec; 0.566 sec/batch)\n",
      "2017-05-06 22:48:33.639139: step 30, loss = 2.87 (247.4 examples/sec; 0.517 sec/batch)\n",
      "2017-05-06 22:48:39.001201: step 40, loss = 2.82 (238.7 examples/sec; 0.536 sec/batch)\n",
      "2017-05-06 22:48:44.161783: step 50, loss = 2.67 (248.0 examples/sec; 0.516 sec/batch)\n",
      "2017-05-06 22:48:49.241902: step 60, loss = 2.88 (252.0 examples/sec; 0.508 sec/batch)\n",
      "2017-05-06 22:48:55.223252: step 70, loss = 2.69 (214.0 examples/sec; 0.598 sec/batch)\n",
      "2017-05-06 22:49:00.843540: step 80, loss = 2.70 (227.7 examples/sec; 0.562 sec/batch)\n",
      "2017-05-06 22:49:06.584898: step 90, loss = 2.71 (222.9 examples/sec; 0.574 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.79293\n",
      "2017-05-06 22:49:11.812669: step 100, loss = 2.76 (244.8 examples/sec; 0.523 sec/batch)\n",
      "2017-05-06 22:49:17.266370: step 110, loss = 2.60 (234.7 examples/sec; 0.545 sec/batch)\n",
      "2017-05-06 22:49:22.584610: step 120, loss = 2.61 (240.7 examples/sec; 0.532 sec/batch)\n",
      "2017-05-06 22:49:27.961055: step 130, loss = 2.55 (238.1 examples/sec; 0.538 sec/batch)\n",
      "2017-05-06 22:49:33.833957: step 140, loss = 2.39 (218.0 examples/sec; 0.587 sec/batch)\n",
      "2017-05-06 22:49:38.956998: step 150, loss = 2.44 (249.9 examples/sec; 0.512 sec/batch)\n",
      "2017-05-06 22:49:43.806423: step 160, loss = 2.50 (263.9 examples/sec; 0.485 sec/batch)\n",
      "2017-05-06 22:49:48.915889: step 170, loss = 2.50 (250.5 examples/sec; 0.511 sec/batch)\n",
      "2017-05-06 22:49:53.941073: step 180, loss = 2.45 (254.7 examples/sec; 0.503 sec/batch)\n",
      "2017-05-06 22:49:58.952649: step 190, loss = 2.33 (255.4 examples/sec; 0.501 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.91248\n",
      "2017-05-06 22:50:04.094938: step 200, loss = 2.39 (248.9 examples/sec; 0.514 sec/batch)\n",
      "2017-05-06 22:50:09.033904: step 210, loss = 2.33 (259.2 examples/sec; 0.494 sec/batch)\n",
      "2017-05-06 22:50:14.012966: step 220, loss = 2.54 (257.1 examples/sec; 0.498 sec/batch)\n",
      "2017-05-06 22:50:19.002344: step 230, loss = 2.39 (256.5 examples/sec; 0.499 sec/batch)\n",
      "2017-05-06 22:50:23.975750: step 240, loss = 2.38 (257.4 examples/sec; 0.497 sec/batch)\n",
      "2017-05-06 22:50:29.059705: step 250, loss = 2.30 (251.8 examples/sec; 0.508 sec/batch)\n",
      "2017-05-06 22:50:34.187290: step 260, loss = 2.32 (249.6 examples/sec; 0.513 sec/batch)\n",
      "2017-05-06 22:50:39.186156: step 270, loss = 2.35 (256.1 examples/sec; 0.500 sec/batch)\n",
      "2017-05-06 22:50:44.236093: step 280, loss = 2.20 (253.5 examples/sec; 0.505 sec/batch)\n",
      "2017-05-06 22:50:49.266488: step 290, loss = 2.31 (254.5 examples/sec; 0.503 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.9868\n",
      "2017-05-06 22:50:54.419421: step 300, loss = 2.30 (248.4 examples/sec; 0.515 sec/batch)\n",
      "2017-05-06 22:50:59.547110: step 310, loss = 2.22 (249.6 examples/sec; 0.513 sec/batch)\n",
      "2017-05-06 22:51:04.549750: step 320, loss = 2.16 (255.9 examples/sec; 0.500 sec/batch)\n",
      "2017-05-06 22:51:09.531432: step 330, loss = 2.26 (256.9 examples/sec; 0.498 sec/batch)\n",
      "2017-05-06 22:51:14.447439: step 340, loss = 2.18 (260.4 examples/sec; 0.492 sec/batch)\n",
      "2017-05-06 22:51:19.410264: step 350, loss = 2.30 (257.9 examples/sec; 0.496 sec/batch)\n",
      "2017-05-06 22:51:24.273705: step 360, loss = 1.94 (263.2 examples/sec; 0.486 sec/batch)\n",
      "2017-05-06 22:51:29.377536: step 370, loss = 2.20 (250.8 examples/sec; 0.510 sec/batch)\n",
      "2017-05-06 22:51:34.404071: step 380, loss = 2.18 (254.6 examples/sec; 0.503 sec/batch)\n",
      "2017-05-06 22:51:39.420507: step 390, loss = 2.11 (255.2 examples/sec; 0.502 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 2.00014\n",
      "2017-05-06 22:51:44.422610: step 400, loss = 2.24 (255.9 examples/sec; 0.500 sec/batch)\n",
      "2017-05-06 22:51:49.434525: step 410, loss = 2.14 (255.4 examples/sec; 0.501 sec/batch)\n",
      "2017-05-06 22:51:54.450817: step 420, loss = 2.07 (255.2 examples/sec; 0.502 sec/batch)\n",
      "2017-05-06 22:51:59.494468: step 430, loss = 2.20 (253.8 examples/sec; 0.504 sec/batch)\n",
      "2017-05-06 22:52:04.452629: step 440, loss = 2.12 (258.2 examples/sec; 0.496 sec/batch)\n",
      "2017-05-06 22:52:09.383287: step 450, loss = 2.31 (259.6 examples/sec; 0.493 sec/batch)\n",
      "2017-05-06 22:52:14.374265: step 460, loss = 2.35 (256.5 examples/sec; 0.499 sec/batch)\n",
      "2017-05-06 22:52:19.378702: step 470, loss = 2.17 (255.8 examples/sec; 0.500 sec/batch)\n",
      "2017-05-06 22:52:24.370892: step 480, loss = 2.04 (256.4 examples/sec; 0.499 sec/batch)\n",
      "2017-05-06 22:52:29.407554: step 490, loss = 2.06 (254.1 examples/sec; 0.504 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.99827\n",
      "2017-05-06 22:52:34.469507: step 500, loss = 2.24 (252.9 examples/sec; 0.506 sec/batch)\n",
      "2017-05-06 22:52:39.467022: step 510, loss = 2.00 (256.1 examples/sec; 0.500 sec/batch)\n",
      "2017-05-06 22:52:44.439886: step 520, loss = 2.05 (257.4 examples/sec; 0.497 sec/batch)\n",
      "2017-05-06 22:52:49.985808: step 530, loss = 2.15 (230.8 examples/sec; 0.555 sec/batch)\n",
      "2017-05-06 22:52:54.950016: step 540, loss = 2.18 (257.8 examples/sec; 0.496 sec/batch)\n",
      "2017-05-06 22:53:00.107654: step 550, loss = 2.22 (248.2 examples/sec; 0.516 sec/batch)\n",
      "2017-05-06 22:53:05.225365: step 560, loss = 2.08 (250.1 examples/sec; 0.512 sec/batch)\n",
      "2017-05-06 22:53:11.441731: step 570, loss = 2.08 (205.9 examples/sec; 0.622 sec/batch)\n",
      "2017-05-06 22:53:17.271664: step 580, loss = 2.05 (219.6 examples/sec; 0.583 sec/batch)\n",
      "2017-05-06 22:53:22.905722: step 590, loss = 1.85 (227.2 examples/sec; 0.563 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.8275\n",
      "2017-05-06 22:53:29.183079: step 600, loss = 2.08 (203.9 examples/sec; 0.628 sec/batch)\n",
      "2017-05-06 22:53:35.538604: step 610, loss = 2.07 (201.4 examples/sec; 0.636 sec/batch)\n",
      "2017-05-06 22:53:40.662039: step 620, loss = 1.88 (249.8 examples/sec; 0.512 sec/batch)\n",
      "2017-05-06 22:53:45.623690: step 630, loss = 2.04 (258.0 examples/sec; 0.496 sec/batch)\n",
      "2017-05-06 22:53:50.770889: step 640, loss = 1.83 (248.7 examples/sec; 0.515 sec/batch)\n",
      "2017-05-06 22:53:55.805011: step 650, loss = 2.23 (254.3 examples/sec; 0.503 sec/batch)\n",
      "2017-05-06 22:54:00.808932: step 660, loss = 2.05 (255.8 examples/sec; 0.500 sec/batch)\n",
      "2017-05-06 22:54:05.805397: step 670, loss = 2.25 (256.2 examples/sec; 0.500 sec/batch)\n",
      "2017-05-06 22:54:11.314079: step 680, loss = 1.96 (232.4 examples/sec; 0.551 sec/batch)\n",
      "2017-05-06 22:54:16.663873: step 690, loss = 1.95 (239.3 examples/sec; 0.535 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.87254\n",
      "2017-05-06 22:54:22.593176: step 700, loss = 1.96 (215.9 examples/sec; 0.593 sec/batch)\n",
      "2017-05-06 22:54:27.556516: step 710, loss = 1.80 (257.9 examples/sec; 0.496 sec/batch)\n",
      "2017-05-06 22:54:32.643321: step 720, loss = 1.93 (251.6 examples/sec; 0.509 sec/batch)\n",
      "2017-05-06 22:54:37.716038: step 730, loss = 1.93 (252.3 examples/sec; 0.507 sec/batch)\n",
      "2017-05-06 22:54:42.856178: step 740, loss = 2.01 (249.0 examples/sec; 0.514 sec/batch)\n",
      "2017-05-06 22:54:48.060052: step 750, loss = 2.02 (246.0 examples/sec; 0.520 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-06 22:54:54.363596: step 760, loss = 2.03 (203.1 examples/sec; 0.630 sec/batch)\n",
      "2017-05-06 22:55:00.751052: step 770, loss = 1.90 (200.4 examples/sec; 0.639 sec/batch)\n",
      "2017-05-06 22:55:06.809670: step 780, loss = 1.94 (211.3 examples/sec; 0.606 sec/batch)\n",
      "2017-05-06 22:55:11.723628: step 790, loss = 1.90 (260.5 examples/sec; 0.491 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.84418\n",
      "2017-05-06 22:55:16.805305: step 800, loss = 1.96 (251.9 examples/sec; 0.508 sec/batch)\n",
      "2017-05-06 22:55:21.721918: step 810, loss = 1.76 (260.3 examples/sec; 0.492 sec/batch)\n",
      "2017-05-06 22:55:26.594863: step 820, loss = 1.93 (262.7 examples/sec; 0.487 sec/batch)\n",
      "2017-05-06 22:55:31.646734: step 830, loss = 1.68 (253.4 examples/sec; 0.505 sec/batch)\n",
      "2017-05-06 22:55:36.549698: step 840, loss = 1.87 (261.1 examples/sec; 0.490 sec/batch)\n",
      "2017-05-06 22:55:41.438358: step 850, loss = 1.89 (261.8 examples/sec; 0.489 sec/batch)\n",
      "2017-05-06 22:55:46.429365: step 860, loss = 1.81 (256.5 examples/sec; 0.499 sec/batch)\n",
      "2017-05-06 22:55:51.380673: step 870, loss = 1.72 (258.5 examples/sec; 0.495 sec/batch)\n",
      "2017-05-06 22:55:56.382844: step 880, loss = 1.84 (255.9 examples/sec; 0.500 sec/batch)\n",
      "2017-05-06 22:56:01.351305: step 890, loss = 1.87 (257.6 examples/sec; 0.497 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 2.01773\n",
      "2017-05-06 22:56:06.379138: step 900, loss = 1.83 (254.6 examples/sec; 0.503 sec/batch)\n",
      "2017-05-06 22:56:11.330340: step 910, loss = 1.87 (258.5 examples/sec; 0.495 sec/batch)\n",
      "2017-05-06 22:56:16.267861: step 920, loss = 1.84 (259.2 examples/sec; 0.494 sec/batch)\n",
      "2017-05-06 22:56:21.300621: step 930, loss = 1.71 (254.3 examples/sec; 0.503 sec/batch)\n",
      "2017-05-06 22:56:26.222415: step 940, loss = 1.82 (260.1 examples/sec; 0.492 sec/batch)\n",
      "2017-05-06 22:56:31.229396: step 950, loss = 1.94 (255.6 examples/sec; 0.501 sec/batch)\n",
      "2017-05-06 22:56:36.259027: step 960, loss = 1.44 (254.5 examples/sec; 0.503 sec/batch)\n",
      "2017-05-06 22:56:41.244002: step 970, loss = 1.80 (256.8 examples/sec; 0.498 sec/batch)\n",
      "2017-05-06 22:56:46.208801: step 980, loss = 1.86 (257.8 examples/sec; 0.496 sec/batch)\n",
      "2017-05-06 22:56:51.223041: step 990, loss = 1.77 (255.3 examples/sec; 0.501 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 2.00766\n",
      "2017-05-06 22:56:56.183130: step 1000, loss = 1.73 (258.1 examples/sec; 0.496 sec/batch)\n",
      "2017-05-06 22:57:01.194773: step 1010, loss = 1.70 (255.4 examples/sec; 0.501 sec/batch)\n",
      "2017-05-06 22:57:06.167942: step 1020, loss = 1.94 (257.4 examples/sec; 0.497 sec/batch)\n",
      "2017-05-06 22:57:11.126057: step 1030, loss = 1.89 (258.2 examples/sec; 0.496 sec/batch)\n",
      "2017-05-06 22:57:16.061737: step 1040, loss = 1.81 (259.3 examples/sec; 0.494 sec/batch)\n",
      "2017-05-06 22:57:20.115899: step 1050, loss = 1.78 (315.7 examples/sec; 0.405 sec/batch)\n",
      "2017-05-06 22:57:25.033121: step 1060, loss = 1.71 (260.3 examples/sec; 0.492 sec/batch)\n",
      "2017-05-06 22:57:30.052249: step 1070, loss = 1.78 (255.0 examples/sec; 0.502 sec/batch)\n",
      "2017-05-06 22:57:35.043915: step 1080, loss = 1.75 (256.4 examples/sec; 0.499 sec/batch)\n",
      "2017-05-06 22:57:39.980314: step 1090, loss = 1.70 (259.3 examples/sec; 0.494 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 2.05639\n",
      "2017-05-06 22:57:44.815563: step 1100, loss = 1.62 (264.7 examples/sec; 0.484 sec/batch)\n",
      "2017-05-06 22:57:49.706036: step 1110, loss = 1.88 (261.7 examples/sec; 0.489 sec/batch)\n",
      "2017-05-06 22:57:54.605454: step 1120, loss = 1.58 (261.3 examples/sec; 0.490 sec/batch)\n",
      "2017-05-06 22:57:59.669403: step 1130, loss = 2.10 (252.8 examples/sec; 0.506 sec/batch)\n",
      "2017-05-06 22:58:04.592029: step 1140, loss = 1.77 (260.0 examples/sec; 0.492 sec/batch)\n",
      "2017-05-06 22:58:09.563562: step 1150, loss = 1.76 (257.5 examples/sec; 0.497 sec/batch)\n",
      "2017-05-06 22:58:14.527493: step 1160, loss = 1.59 (257.9 examples/sec; 0.496 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 1164 into /tmp/cifar10_train_network2/model.ckpt.\n",
      "2017-05-06 22:58:21.115737: step 1170, loss = 1.84 (194.3 examples/sec; 0.659 sec/batch)\n",
      "2017-05-06 22:58:26.063769: step 1180, loss = 1.62 (258.7 examples/sec; 0.495 sec/batch)\n",
      "2017-05-06 22:58:31.133746: step 1190, loss = 1.67 (252.5 examples/sec; 0.507 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.9466\n",
      "2017-05-06 22:58:36.180954: step 1200, loss = 1.62 (253.6 examples/sec; 0.505 sec/batch)\n",
      "2017-05-06 22:58:41.085321: step 1210, loss = 1.65 (261.0 examples/sec; 0.490 sec/batch)\n",
      "2017-05-06 22:58:46.057107: step 1220, loss = 1.58 (257.5 examples/sec; 0.497 sec/batch)\n",
      "2017-05-06 22:58:50.971516: step 1230, loss = 1.72 (260.5 examples/sec; 0.491 sec/batch)\n",
      "2017-05-06 22:58:55.923741: step 1240, loss = 1.69 (258.5 examples/sec; 0.495 sec/batch)\n",
      "2017-05-06 22:59:00.825788: step 1250, loss = 1.62 (261.1 examples/sec; 0.490 sec/batch)\n",
      "2017-05-06 22:59:05.893244: step 1260, loss = 1.61 (252.6 examples/sec; 0.507 sec/batch)\n",
      "2017-05-06 22:59:10.847166: step 1270, loss = 1.49 (258.4 examples/sec; 0.495 sec/batch)\n",
      "2017-05-06 22:59:15.878824: step 1280, loss = 1.55 (254.4 examples/sec; 0.503 sec/batch)\n",
      "2017-05-06 22:59:20.870334: step 1290, loss = 1.58 (256.4 examples/sec; 0.499 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 2.0139\n",
      "2017-05-06 22:59:25.835912: step 1300, loss = 1.65 (257.8 examples/sec; 0.497 sec/batch)\n",
      "2017-05-06 22:59:30.804594: step 1310, loss = 1.55 (257.6 examples/sec; 0.497 sec/batch)\n",
      "2017-05-06 22:59:35.876512: step 1320, loss = 1.51 (252.4 examples/sec; 0.507 sec/batch)\n",
      "2017-05-06 22:59:40.742548: step 1330, loss = 1.77 (263.0 examples/sec; 0.487 sec/batch)\n",
      "2017-05-06 22:59:45.613387: step 1340, loss = 1.77 (262.8 examples/sec; 0.487 sec/batch)\n",
      "2017-05-06 22:59:50.496940: step 1350, loss = 1.65 (262.1 examples/sec; 0.488 sec/batch)\n",
      "2017-05-06 22:59:55.431754: step 1360, loss = 1.65 (259.4 examples/sec; 0.493 sec/batch)\n",
      "2017-05-06 23:00:00.343581: step 1370, loss = 1.52 (260.6 examples/sec; 0.491 sec/batch)\n",
      "2017-05-06 23:00:05.409097: step 1380, loss = 1.49 (252.7 examples/sec; 0.507 sec/batch)\n",
      "2017-05-06 23:00:10.358850: step 1390, loss = 1.48 (258.6 examples/sec; 0.495 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 2.01933\n",
      "2017-05-06 23:00:15.362635: step 1400, loss = 1.85 (255.8 examples/sec; 0.500 sec/batch)\n",
      "2017-05-06 23:00:20.331641: step 1410, loss = 1.76 (257.6 examples/sec; 0.497 sec/batch)\n",
      "2017-05-06 23:00:25.252945: step 1420, loss = 1.37 (260.1 examples/sec; 0.492 sec/batch)\n",
      "2017-05-06 23:00:30.209897: step 1430, loss = 1.58 (258.2 examples/sec; 0.496 sec/batch)\n",
      "2017-05-06 23:00:35.334205: step 1440, loss = 1.56 (249.8 examples/sec; 0.512 sec/batch)\n",
      "2017-05-06 23:00:40.319329: step 1450, loss = 1.46 (256.8 examples/sec; 0.499 sec/batch)\n",
      "2017-05-06 23:00:45.328312: step 1460, loss = 1.61 (255.5 examples/sec; 0.501 sec/batch)\n",
      "2017-05-06 23:00:50.269965: step 1470, loss = 1.60 (259.0 examples/sec; 0.494 sec/batch)\n",
      "2017-05-06 23:00:55.227162: step 1480, loss = 1.64 (258.2 examples/sec; 0.496 sec/batch)\n",
      "2017-05-06 23:01:00.144972: step 1490, loss = 1.53 (260.3 examples/sec; 0.492 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 2.00519\n",
      "2017-05-06 23:01:05.229973: step 1500, loss = 1.45 (251.7 examples/sec; 0.509 sec/batch)\n",
      "2017-05-06 23:01:10.165641: step 1510, loss = 1.39 (259.3 examples/sec; 0.494 sec/batch)\n",
      "2017-05-06 23:01:15.023530: step 1520, loss = 1.45 (263.5 examples/sec; 0.486 sec/batch)\n",
      "2017-05-06 23:01:19.945754: step 1530, loss = 1.87 (260.0 examples/sec; 0.492 sec/batch)\n",
      "2017-05-06 23:01:24.914999: step 1540, loss = 1.50 (257.6 examples/sec; 0.497 sec/batch)\n",
      "2017-05-06 23:01:29.896929: step 1550, loss = 1.51 (256.9 examples/sec; 0.498 sec/batch)\n",
      "2017-05-06 23:01:34.938455: step 1560, loss = 1.39 (253.9 examples/sec; 0.504 sec/batch)\n",
      "2017-05-06 23:01:39.849362: step 1570, loss = 1.47 (260.6 examples/sec; 0.491 sec/batch)\n",
      "2017-05-06 23:01:44.733075: step 1580, loss = 1.57 (262.1 examples/sec; 0.488 sec/batch)\n",
      "2017-05-06 23:01:49.673304: step 1590, loss = 1.50 (259.1 examples/sec; 0.494 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 2.02227\n",
      "2017-05-06 23:01:54.678293: step 1600, loss = 1.45 (255.7 examples/sec; 0.500 sec/batch)\n",
      "2017-05-06 23:01:59.766562: step 1610, loss = 1.76 (251.6 examples/sec; 0.509 sec/batch)\n",
      "2017-05-06 23:02:04.821005: step 1620, loss = 1.71 (253.2 examples/sec; 0.505 sec/batch)\n",
      "2017-05-06 23:02:09.848096: step 1630, loss = 1.54 (254.6 examples/sec; 0.503 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-06 23:02:14.893379: step 1640, loss = 1.60 (253.7 examples/sec; 0.505 sec/batch)\n",
      "2017-05-06 23:02:19.806334: step 1650, loss = 1.32 (260.5 examples/sec; 0.491 sec/batch)\n",
      "2017-05-06 23:02:24.777829: step 1660, loss = 1.50 (257.5 examples/sec; 0.497 sec/batch)\n",
      "2017-05-06 23:02:29.718757: step 1670, loss = 1.62 (259.1 examples/sec; 0.494 sec/batch)\n",
      "2017-05-06 23:02:34.788900: step 1680, loss = 1.54 (252.5 examples/sec; 0.507 sec/batch)\n",
      "2017-05-06 23:02:39.705027: step 1690, loss = 1.38 (260.4 examples/sec; 0.492 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.99778\n",
      "2017-05-06 23:02:44.739295: step 1700, loss = 1.59 (254.3 examples/sec; 0.503 sec/batch)\n",
      "2017-05-06 23:02:49.625710: step 1710, loss = 1.65 (262.0 examples/sec; 0.489 sec/batch)\n",
      "2017-05-06 23:02:54.677322: step 1720, loss = 1.51 (253.4 examples/sec; 0.505 sec/batch)\n",
      "2017-05-06 23:02:59.582491: step 1730, loss = 1.23 (260.9 examples/sec; 0.491 sec/batch)\n",
      "2017-05-06 23:03:04.600461: step 1740, loss = 1.68 (255.1 examples/sec; 0.502 sec/batch)\n",
      "2017-05-06 23:03:09.537945: step 1750, loss = 1.36 (259.2 examples/sec; 0.494 sec/batch)\n",
      "2017-05-06 23:03:14.416907: step 1760, loss = 1.53 (262.4 examples/sec; 0.488 sec/batch)\n",
      "2017-05-06 23:03:19.326557: step 1770, loss = 1.66 (260.7 examples/sec; 0.491 sec/batch)\n",
      "2017-05-06 23:03:24.364351: step 1780, loss = 1.40 (254.1 examples/sec; 0.504 sec/batch)\n",
      "2017-05-06 23:03:29.393317: step 1790, loss = 1.51 (254.5 examples/sec; 0.503 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 2.01008\n",
      "2017-05-06 23:03:34.487803: step 1800, loss = 1.36 (251.3 examples/sec; 0.509 sec/batch)\n",
      "2017-05-06 23:03:39.418453: step 1810, loss = 1.36 (259.6 examples/sec; 0.493 sec/batch)\n",
      "2017-05-06 23:03:44.288154: step 1820, loss = 1.42 (262.8 examples/sec; 0.487 sec/batch)\n",
      "2017-05-06 23:03:49.231061: step 1830, loss = 1.52 (259.0 examples/sec; 0.494 sec/batch)\n",
      "2017-05-06 23:03:54.132624: step 1840, loss = 1.30 (261.1 examples/sec; 0.490 sec/batch)\n",
      "2017-05-06 23:03:59.306704: step 1850, loss = 1.53 (247.4 examples/sec; 0.517 sec/batch)\n",
      "2017-05-06 23:04:05.776782: step 1860, loss = 1.32 (197.8 examples/sec; 0.647 sec/batch)\n",
      "2017-05-06 23:04:12.110755: step 1870, loss = 1.39 (202.1 examples/sec; 0.633 sec/batch)\n",
      "2017-05-06 23:04:17.547848: step 1880, loss = 1.42 (235.4 examples/sec; 0.544 sec/batch)\n",
      "2017-05-06 23:04:22.500949: step 1890, loss = 1.34 (258.4 examples/sec; 0.495 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.8851\n",
      "2017-05-06 23:04:27.533851: step 1900, loss = 1.45 (254.3 examples/sec; 0.503 sec/batch)\n",
      "2017-05-06 23:04:32.553101: step 1910, loss = 1.44 (255.0 examples/sec; 0.502 sec/batch)\n",
      "2017-05-06 23:04:37.595114: step 1920, loss = 1.39 (253.9 examples/sec; 0.504 sec/batch)\n",
      "2017-05-06 23:04:42.607492: step 1930, loss = 1.30 (255.4 examples/sec; 0.501 sec/batch)\n",
      "2017-05-06 23:04:47.594098: step 1940, loss = 1.33 (256.7 examples/sec; 0.499 sec/batch)\n",
      "2017-05-06 23:04:52.501610: step 1950, loss = 1.42 (260.8 examples/sec; 0.491 sec/batch)\n",
      "2017-05-06 23:04:57.529385: step 1960, loss = 1.31 (254.6 examples/sec; 0.503 sec/batch)\n",
      "2017-05-06 23:05:02.481944: step 1970, loss = 1.41 (258.5 examples/sec; 0.495 sec/batch)\n",
      "2017-05-06 23:05:07.523690: step 1980, loss = 1.49 (253.9 examples/sec; 0.504 sec/batch)\n",
      "2017-05-06 23:05:12.507536: step 1990, loss = 1.26 (256.8 examples/sec; 0.498 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.99989\n",
      "2017-05-06 23:05:17.527701: step 2000, loss = 1.52 (255.0 examples/sec; 0.502 sec/batch)\n",
      "2017-05-06 23:05:22.503830: step 2010, loss = 1.40 (257.2 examples/sec; 0.498 sec/batch)\n",
      "2017-05-06 23:05:27.449065: step 2020, loss = 1.53 (258.8 examples/sec; 0.495 sec/batch)\n",
      "2017-05-06 23:05:32.412600: step 2030, loss = 1.42 (257.9 examples/sec; 0.496 sec/batch)\n",
      "2017-05-06 23:05:37.441659: step 2040, loss = 1.44 (254.5 examples/sec; 0.503 sec/batch)\n",
      "2017-05-06 23:05:42.404075: step 2050, loss = 1.38 (257.9 examples/sec; 0.496 sec/batch)\n",
      "2017-05-06 23:05:47.348080: step 2060, loss = 1.77 (258.9 examples/sec; 0.494 sec/batch)\n",
      "2017-05-06 23:05:52.270222: step 2070, loss = 1.32 (260.0 examples/sec; 0.492 sec/batch)\n",
      "2017-05-06 23:05:57.199443: step 2080, loss = 1.22 (259.7 examples/sec; 0.493 sec/batch)\n",
      "2017-05-06 23:06:02.149616: step 2090, loss = 1.38 (258.6 examples/sec; 0.495 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 2.00944\n",
      "2017-05-06 23:06:07.305075: step 2100, loss = 1.43 (248.3 examples/sec; 0.516 sec/batch)\n",
      "2017-05-06 23:06:12.187022: step 2110, loss = 1.39 (262.2 examples/sec; 0.488 sec/batch)\n",
      "2017-05-06 23:06:17.133377: step 2120, loss = 1.40 (258.8 examples/sec; 0.495 sec/batch)\n",
      "2017-05-06 23:06:22.077892: step 2130, loss = 1.34 (258.9 examples/sec; 0.494 sec/batch)\n",
      "2017-05-06 23:06:27.005423: step 2140, loss = 1.36 (259.8 examples/sec; 0.493 sec/batch)\n",
      "2017-05-06 23:06:32.008906: step 2150, loss = 1.42 (255.8 examples/sec; 0.500 sec/batch)\n",
      "2017-05-06 23:06:37.072902: step 2160, loss = 1.44 (252.8 examples/sec; 0.506 sec/batch)\n",
      "2017-05-06 23:06:42.037938: step 2170, loss = 1.34 (257.8 examples/sec; 0.497 sec/batch)\n",
      "2017-05-06 23:06:46.993464: step 2180, loss = 1.31 (258.3 examples/sec; 0.496 sec/batch)\n",
      "2017-05-06 23:06:51.978822: step 2190, loss = 1.33 (256.8 examples/sec; 0.499 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 2.01329\n",
      "2017-05-06 23:06:56.976104: step 2200, loss = 1.60 (256.1 examples/sec; 0.500 sec/batch)\n",
      "2017-05-06 23:07:01.926774: step 2210, loss = 1.32 (258.6 examples/sec; 0.495 sec/batch)\n",
      "2017-05-06 23:07:06.932615: step 2220, loss = 1.32 (255.7 examples/sec; 0.501 sec/batch)\n",
      "2017-05-06 23:07:12.000021: step 2230, loss = 1.31 (252.6 examples/sec; 0.507 sec/batch)\n",
      "2017-05-06 23:07:16.987242: step 2240, loss = 1.39 (256.7 examples/sec; 0.499 sec/batch)\n",
      "2017-05-06 23:07:21.248063: step 2250, loss = 1.29 (300.4 examples/sec; 0.426 sec/batch)\n",
      "2017-05-06 23:07:26.152094: step 2260, loss = 1.29 (261.0 examples/sec; 0.490 sec/batch)\n",
      "2017-05-06 23:07:31.163702: step 2270, loss = 1.24 (255.4 examples/sec; 0.501 sec/batch)\n",
      "2017-05-06 23:07:36.207962: step 2280, loss = 1.32 (253.8 examples/sec; 0.504 sec/batch)\n",
      "2017-05-06 23:07:41.296159: step 2290, loss = 1.41 (251.6 examples/sec; 0.509 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 2.02878\n",
      "2017-05-06 23:07:46.262399: step 2300, loss = 1.22 (257.7 examples/sec; 0.497 sec/batch)\n",
      "2017-05-06 23:07:51.179847: step 2310, loss = 1.32 (260.3 examples/sec; 0.492 sec/batch)\n",
      "2017-05-06 23:07:56.156310: step 2320, loss = 1.44 (257.2 examples/sec; 0.498 sec/batch)\n",
      "2017-05-06 23:08:01.062858: step 2330, loss = 1.31 (260.9 examples/sec; 0.491 sec/batch)\n",
      "2017-05-06 23:08:06.111379: step 2340, loss = 1.06 (253.5 examples/sec; 0.505 sec/batch)\n",
      "2017-05-06 23:08:11.124045: step 2350, loss = 1.26 (255.4 examples/sec; 0.501 sec/batch)\n",
      "2017-05-06 23:08:16.008510: step 2360, loss = 1.37 (262.1 examples/sec; 0.488 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 2362 into /tmp/cifar10_train_network2/model.ckpt.\n",
      "2017-05-06 23:08:22.413978: step 2370, loss = 1.34 (199.8 examples/sec; 0.641 sec/batch)\n",
      "2017-05-06 23:08:27.443168: step 2380, loss = 1.43 (254.5 examples/sec; 0.503 sec/batch)\n",
      "2017-05-06 23:08:32.421031: step 2390, loss = 1.17 (257.1 examples/sec; 0.498 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.9413\n",
      "2017-05-06 23:08:37.780070: step 2400, loss = 1.22 (238.8 examples/sec; 0.536 sec/batch)\n",
      "2017-05-06 23:08:44.522380: step 2410, loss = 1.42 (189.8 examples/sec; 0.674 sec/batch)\n",
      "2017-05-06 23:08:50.176733: step 2420, loss = 1.38 (226.4 examples/sec; 0.565 sec/batch)\n",
      "2017-05-06 23:08:55.731114: step 2430, loss = 1.17 (230.4 examples/sec; 0.555 sec/batch)\n",
      "2017-05-06 23:09:00.799151: step 2440, loss = 1.17 (252.6 examples/sec; 0.507 sec/batch)\n",
      "2017-05-06 23:09:06.018640: step 2450, loss = 1.33 (245.2 examples/sec; 0.522 sec/batch)\n",
      "2017-05-06 23:09:11.719595: step 2460, loss = 1.34 (224.5 examples/sec; 0.570 sec/batch)\n",
      "2017-05-06 23:09:17.458993: step 2470, loss = 1.26 (223.0 examples/sec; 0.574 sec/batch)\n",
      "2017-05-06 23:09:22.732562: step 2480, loss = 1.41 (242.7 examples/sec; 0.527 sec/batch)\n",
      "2017-05-06 23:09:28.171463: step 2490, loss = 1.25 (235.3 examples/sec; 0.544 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.79706\n",
      "2017-05-06 23:09:33.419014: step 2500, loss = 1.46 (243.9 examples/sec; 0.525 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-06 23:09:38.646359: step 2510, loss = 1.21 (244.9 examples/sec; 0.523 sec/batch)\n",
      "2017-05-06 23:09:43.738386: step 2520, loss = 1.36 (251.4 examples/sec; 0.509 sec/batch)\n",
      "2017-05-06 23:09:49.066133: step 2530, loss = 1.14 (240.3 examples/sec; 0.533 sec/batch)\n",
      "2017-05-06 23:09:54.112822: step 2540, loss = 1.17 (253.6 examples/sec; 0.505 sec/batch)\n",
      "2017-05-06 23:09:59.528813: step 2550, loss = 1.33 (236.3 examples/sec; 0.542 sec/batch)\n",
      "2017-05-06 23:10:04.694911: step 2560, loss = 1.23 (247.8 examples/sec; 0.517 sec/batch)\n",
      "2017-05-06 23:10:09.777755: step 2570, loss = 1.26 (251.8 examples/sec; 0.508 sec/batch)\n",
      "2017-05-06 23:10:14.967814: step 2580, loss = 1.20 (246.6 examples/sec; 0.519 sec/batch)\n",
      "2017-05-06 23:10:20.218150: step 2590, loss = 1.20 (243.8 examples/sec; 0.525 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.92086\n",
      "2017-05-06 23:10:25.484543: step 2600, loss = 1.44 (243.1 examples/sec; 0.527 sec/batch)\n",
      "2017-05-06 23:10:30.764891: step 2610, loss = 1.28 (242.4 examples/sec; 0.528 sec/batch)\n",
      "2017-05-06 23:10:37.548956: step 2620, loss = 1.18 (188.7 examples/sec; 0.678 sec/batch)\n",
      "2017-05-06 23:10:43.826162: step 2630, loss = 1.07 (203.9 examples/sec; 0.628 sec/batch)\n",
      "2017-05-06 23:10:48.942608: step 2640, loss = 1.19 (250.2 examples/sec; 0.512 sec/batch)\n",
      "2017-05-06 23:10:53.928032: step 2650, loss = 1.35 (256.7 examples/sec; 0.499 sec/batch)\n",
      "2017-05-06 23:10:58.892188: step 2660, loss = 1.19 (257.8 examples/sec; 0.496 sec/batch)\n",
      "2017-05-06 23:11:03.873659: step 2670, loss = 1.36 (257.0 examples/sec; 0.498 sec/batch)\n",
      "2017-05-06 23:11:08.869085: step 2680, loss = 1.27 (256.2 examples/sec; 0.500 sec/batch)\n",
      "2017-05-06 23:11:13.940929: step 2690, loss = 1.17 (252.4 examples/sec; 0.507 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.86966\n",
      "2017-05-06 23:11:18.969616: step 2700, loss = 1.18 (254.5 examples/sec; 0.503 sec/batch)\n",
      "2017-05-06 23:11:23.950018: step 2710, loss = 0.99 (257.0 examples/sec; 0.498 sec/batch)\n",
      "2017-05-06 23:11:28.921488: step 2720, loss = 1.29 (257.5 examples/sec; 0.497 sec/batch)\n",
      "2017-05-06 23:11:33.948980: step 2730, loss = 1.30 (254.6 examples/sec; 0.503 sec/batch)\n",
      "2017-05-06 23:11:39.001896: step 2740, loss = 1.17 (253.3 examples/sec; 0.505 sec/batch)\n",
      "2017-05-06 23:11:44.022426: step 2750, loss = 1.28 (255.0 examples/sec; 0.502 sec/batch)\n",
      "2017-05-06 23:11:49.026878: step 2760, loss = 1.31 (255.8 examples/sec; 0.500 sec/batch)\n",
      "2017-05-06 23:11:54.064259: step 2770, loss = 1.12 (254.1 examples/sec; 0.504 sec/batch)\n",
      "2017-05-06 23:11:58.975149: step 2780, loss = 1.29 (260.6 examples/sec; 0.491 sec/batch)\n",
      "2017-05-06 23:12:04.007394: step 2790, loss = 1.35 (254.4 examples/sec; 0.503 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.99514\n",
      "2017-05-06 23:12:09.103717: step 2800, loss = 1.12 (251.2 examples/sec; 0.510 sec/batch)\n",
      "2017-05-06 23:12:14.053336: step 2810, loss = 1.11 (258.6 examples/sec; 0.495 sec/batch)\n",
      "2017-05-06 23:12:18.970462: step 2820, loss = 1.31 (260.3 examples/sec; 0.492 sec/batch)\n",
      "2017-05-06 23:12:23.994272: step 2830, loss = 1.06 (254.8 examples/sec; 0.502 sec/batch)\n",
      "2017-05-06 23:12:28.946642: step 2840, loss = 1.33 (258.5 examples/sec; 0.495 sec/batch)\n",
      "2017-05-06 23:12:33.912213: step 2850, loss = 1.15 (257.8 examples/sec; 0.497 sec/batch)\n",
      "2017-05-06 23:12:38.948500: step 2860, loss = 1.27 (254.2 examples/sec; 0.504 sec/batch)\n",
      "2017-05-06 23:12:43.877161: step 2870, loss = 1.06 (259.7 examples/sec; 0.493 sec/batch)\n",
      "2017-05-06 23:12:48.857658: step 2880, loss = 1.16 (257.0 examples/sec; 0.498 sec/batch)\n",
      "2017-05-06 23:12:53.850117: step 2890, loss = 1.12 (256.4 examples/sec; 0.499 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 2.00859\n",
      "2017-05-06 23:12:58.871993: step 2900, loss = 1.28 (254.9 examples/sec; 0.502 sec/batch)\n",
      "2017-05-06 23:13:03.863557: step 2910, loss = 1.17 (256.4 examples/sec; 0.499 sec/batch)\n",
      "2017-05-06 23:13:08.829708: step 2920, loss = 1.25 (257.7 examples/sec; 0.497 sec/batch)\n",
      "2017-05-06 23:13:13.961276: step 2930, loss = 1.43 (249.4 examples/sec; 0.513 sec/batch)\n",
      "2017-05-06 23:13:18.878363: step 2940, loss = 1.08 (260.3 examples/sec; 0.492 sec/batch)\n",
      "2017-05-06 23:13:23.823442: step 2950, loss = 1.15 (258.8 examples/sec; 0.495 sec/batch)\n",
      "2017-05-06 23:13:28.761316: step 2960, loss = 1.17 (259.2 examples/sec; 0.494 sec/batch)\n",
      "2017-05-06 23:13:33.783386: step 2970, loss = 1.11 (254.9 examples/sec; 0.502 sec/batch)\n",
      "2017-05-06 23:13:38.833634: step 2980, loss = 1.19 (253.5 examples/sec; 0.505 sec/batch)\n",
      "2017-05-06 23:13:43.666529: step 2990, loss = 1.35 (264.9 examples/sec; 0.483 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 2.0051\n",
      "2017-05-06 23:13:48.746612: step 3000, loss = 1.25 (252.0 examples/sec; 0.508 sec/batch)\n",
      "2017-05-06 23:13:53.645818: step 3010, loss = 1.09 (261.3 examples/sec; 0.490 sec/batch)\n",
      "2017-05-06 23:13:58.542568: step 3020, loss = 1.09 (261.4 examples/sec; 0.490 sec/batch)\n",
      "2017-05-06 23:14:03.521956: step 3030, loss = 1.19 (257.1 examples/sec; 0.498 sec/batch)\n",
      "2017-05-06 23:14:08.574337: step 3040, loss = 1.20 (253.3 examples/sec; 0.505 sec/batch)\n",
      "2017-05-06 23:14:13.600093: step 3050, loss = 1.13 (254.7 examples/sec; 0.503 sec/batch)\n",
      "2017-05-06 23:14:18.614492: step 3060, loss = 1.11 (255.3 examples/sec; 0.501 sec/batch)\n",
      "2017-05-06 23:14:23.613181: step 3070, loss = 1.19 (256.1 examples/sec; 0.500 sec/batch)\n",
      "2017-05-06 23:14:28.594152: step 3080, loss = 1.37 (257.0 examples/sec; 0.498 sec/batch)\n",
      "2017-05-06 23:14:33.502846: step 3090, loss = 1.22 (260.8 examples/sec; 0.491 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 2.00516\n",
      "2017-05-06 23:14:38.629659: step 3100, loss = 1.21 (249.7 examples/sec; 0.513 sec/batch)\n",
      "2017-05-06 23:14:43.573133: step 3110, loss = 1.13 (258.9 examples/sec; 0.494 sec/batch)\n",
      "2017-05-06 23:14:48.662610: step 3120, loss = 1.26 (251.5 examples/sec; 0.509 sec/batch)\n",
      "2017-05-06 23:14:53.540077: step 3130, loss = 1.17 (262.4 examples/sec; 0.488 sec/batch)\n",
      "2017-05-06 23:14:58.438848: step 3140, loss = 1.14 (261.3 examples/sec; 0.490 sec/batch)\n",
      "2017-05-06 23:15:03.383284: step 3150, loss = 1.16 (258.9 examples/sec; 0.494 sec/batch)\n",
      "2017-05-06 23:15:08.344273: step 3160, loss = 1.11 (258.0 examples/sec; 0.496 sec/batch)\n",
      "2017-05-06 23:15:13.359506: step 3170, loss = 1.33 (255.2 examples/sec; 0.502 sec/batch)\n",
      "2017-05-06 23:15:18.383458: step 3180, loss = 1.35 (254.8 examples/sec; 0.502 sec/batch)\n",
      "2017-05-06 23:15:23.338208: step 3190, loss = 1.01 (258.3 examples/sec; 0.495 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 2.00648\n",
      "2017-05-06 23:15:28.468422: step 3200, loss = 1.14 (249.5 examples/sec; 0.513 sec/batch)\n",
      "2017-05-06 23:15:33.391651: step 3210, loss = 1.21 (260.0 examples/sec; 0.492 sec/batch)\n",
      "2017-05-06 23:15:38.444498: step 3220, loss = 1.08 (253.3 examples/sec; 0.505 sec/batch)\n",
      "2017-05-06 23:15:43.376079: step 3230, loss = 1.31 (259.6 examples/sec; 0.493 sec/batch)\n",
      "2017-05-06 23:15:48.423788: step 3240, loss = 1.11 (253.6 examples/sec; 0.505 sec/batch)\n",
      "2017-05-06 23:15:53.476173: step 3250, loss = 1.25 (253.3 examples/sec; 0.505 sec/batch)\n",
      "2017-05-06 23:15:58.407773: step 3260, loss = 1.24 (259.6 examples/sec; 0.493 sec/batch)\n",
      "2017-05-06 23:16:03.390345: step 3270, loss = 1.16 (256.9 examples/sec; 0.498 sec/batch)\n",
      "2017-05-06 23:16:08.358926: step 3280, loss = 1.13 (257.6 examples/sec; 0.497 sec/batch)\n",
      "2017-05-06 23:16:13.447093: step 3290, loss = 1.37 (251.6 examples/sec; 0.509 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.99974\n",
      "2017-05-06 23:16:18.454119: step 3300, loss = 1.36 (255.6 examples/sec; 0.501 sec/batch)\n",
      "2017-05-06 23:16:23.438987: step 3310, loss = 1.20 (256.8 examples/sec; 0.498 sec/batch)\n",
      "2017-05-06 23:16:28.408632: step 3320, loss = 1.37 (257.6 examples/sec; 0.497 sec/batch)\n",
      "2017-05-06 23:16:33.251595: step 3330, loss = 0.99 (264.3 examples/sec; 0.484 sec/batch)\n",
      "2017-05-06 23:16:38.313303: step 3340, loss = 1.14 (252.9 examples/sec; 0.506 sec/batch)\n",
      "2017-05-06 23:16:43.239609: step 3350, loss = 1.29 (259.8 examples/sec; 0.493 sec/batch)\n",
      "2017-05-06 23:16:48.175764: step 3360, loss = 1.12 (259.3 examples/sec; 0.494 sec/batch)\n",
      "2017-05-06 23:16:53.118949: step 3370, loss = 1.25 (258.9 examples/sec; 0.494 sec/batch)\n",
      "2017-05-06 23:16:58.154366: step 3380, loss = 1.32 (254.2 examples/sec; 0.504 sec/batch)\n",
      "2017-05-06 23:17:03.076325: step 3390, loss = 1.14 (260.1 examples/sec; 0.492 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.00659\n",
      "2017-05-06 23:17:08.293055: step 3400, loss = 1.24 (245.4 examples/sec; 0.522 sec/batch)\n",
      "2017-05-06 23:17:13.247913: step 3410, loss = 1.35 (258.3 examples/sec; 0.495 sec/batch)\n",
      "2017-05-06 23:17:18.303064: step 3420, loss = 1.20 (253.2 examples/sec; 0.506 sec/batch)\n",
      "2017-05-06 23:17:22.534116: step 3430, loss = 0.93 (302.5 examples/sec; 0.423 sec/batch)\n",
      "2017-05-06 23:17:27.499783: step 3440, loss = 1.00 (257.8 examples/sec; 0.497 sec/batch)\n",
      "2017-05-06 23:17:32.430076: step 3450, loss = 1.16 (259.6 examples/sec; 0.493 sec/batch)\n",
      "2017-05-06 23:17:37.454467: step 3460, loss = 1.26 (254.8 examples/sec; 0.502 sec/batch)\n",
      "2017-05-06 23:17:42.407590: step 3470, loss = 1.15 (258.4 examples/sec; 0.495 sec/batch)\n",
      "2017-05-06 23:17:47.319978: step 3480, loss = 1.23 (260.6 examples/sec; 0.491 sec/batch)\n",
      "2017-05-06 23:17:52.381571: step 3490, loss = 1.24 (252.9 examples/sec; 0.506 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 2.03697\n",
      "2017-05-06 23:17:57.386112: step 3500, loss = 1.22 (255.8 examples/sec; 0.500 sec/batch)\n",
      "2017-05-06 23:18:02.407016: step 3510, loss = 1.28 (254.9 examples/sec; 0.502 sec/batch)\n",
      "2017-05-06 23:18:07.394502: step 3520, loss = 1.32 (256.6 examples/sec; 0.499 sec/batch)\n",
      "2017-05-06 23:18:12.441926: step 3530, loss = 1.09 (253.6 examples/sec; 0.505 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 3540 into /tmp/cifar10_train_network2/model.ckpt.\n",
      "2017-05-06 23:18:19.024426: step 3540, loss = 1.28 (194.5 examples/sec; 0.658 sec/batch)\n",
      "2017-05-06 23:18:23.956248: step 3550, loss = 1.24 (259.5 examples/sec; 0.493 sec/batch)\n",
      "2017-05-06 23:18:28.854288: step 3560, loss = 1.04 (261.3 examples/sec; 0.490 sec/batch)\n",
      "2017-05-06 23:18:33.879207: step 3570, loss = 1.09 (254.7 examples/sec; 0.502 sec/batch)\n",
      "2017-05-06 23:18:38.849358: step 3580, loss = 1.24 (257.5 examples/sec; 0.497 sec/batch)\n",
      "2017-05-06 23:18:43.782688: step 3590, loss = 1.16 (259.5 examples/sec; 0.493 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.94354\n",
      "2017-05-06 23:18:48.840796: step 3600, loss = 1.32 (253.1 examples/sec; 0.506 sec/batch)\n",
      "2017-05-06 23:18:53.760425: step 3610, loss = 1.00 (260.2 examples/sec; 0.492 sec/batch)\n",
      "2017-05-06 23:18:58.709031: step 3620, loss = 1.15 (258.7 examples/sec; 0.495 sec/batch)\n",
      "2017-05-06 23:19:03.914561: step 3630, loss = 1.18 (245.9 examples/sec; 0.521 sec/batch)\n",
      "2017-05-06 23:19:10.039758: step 3640, loss = 1.19 (209.0 examples/sec; 0.613 sec/batch)\n",
      "2017-05-06 23:19:16.004487: step 3650, loss = 1.14 (214.6 examples/sec; 0.596 sec/batch)\n",
      "2017-05-06 23:19:23.210607: step 3660, loss = 1.10 (177.6 examples/sec; 0.721 sec/batch)\n",
      "2017-05-06 23:19:29.059513: step 3670, loss = 1.21 (218.8 examples/sec; 0.585 sec/batch)\n",
      "2017-05-06 23:19:35.208876: step 3680, loss = 0.94 (208.2 examples/sec; 0.615 sec/batch)\n",
      "2017-05-06 23:19:40.327005: step 3690, loss = 1.02 (250.1 examples/sec; 0.512 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.75986\n",
      "2017-05-06 23:19:45.667741: step 3700, loss = 1.11 (239.7 examples/sec; 0.534 sec/batch)\n",
      "2017-05-06 23:19:50.595644: step 3710, loss = 1.17 (259.7 examples/sec; 0.493 sec/batch)\n",
      "2017-05-06 23:19:55.923935: step 3720, loss = 1.12 (240.2 examples/sec; 0.533 sec/batch)\n",
      "2017-05-06 23:20:01.265521: step 3730, loss = 1.18 (239.6 examples/sec; 0.534 sec/batch)\n",
      "2017-05-06 23:20:06.425621: step 3740, loss = 1.21 (248.1 examples/sec; 0.516 sec/batch)\n",
      "2017-05-06 23:20:11.390631: step 3750, loss = 1.10 (257.8 examples/sec; 0.497 sec/batch)\n",
      "2017-05-06 23:20:16.559918: step 3760, loss = 1.05 (247.6 examples/sec; 0.517 sec/batch)\n",
      "2017-05-06 23:20:21.622649: step 3770, loss = 1.24 (252.8 examples/sec; 0.506 sec/batch)\n",
      "2017-05-06 23:20:26.559523: step 3780, loss = 1.19 (259.3 examples/sec; 0.494 sec/batch)\n",
      "2017-05-06 23:20:31.490214: step 3790, loss = 1.24 (259.6 examples/sec; 0.493 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.96584\n",
      "2017-05-06 23:20:36.546498: step 3800, loss = 1.18 (253.2 examples/sec; 0.506 sec/batch)\n",
      "2017-05-06 23:20:41.550759: step 3810, loss = 1.17 (255.8 examples/sec; 0.500 sec/batch)\n",
      "2017-05-06 23:20:46.540620: step 3820, loss = 1.10 (256.5 examples/sec; 0.499 sec/batch)\n",
      "2017-05-06 23:20:51.484568: step 3830, loss = 1.23 (258.9 examples/sec; 0.494 sec/batch)\n",
      "2017-05-06 23:20:56.442424: step 3840, loss = 1.05 (258.2 examples/sec; 0.496 sec/batch)\n",
      "2017-05-06 23:21:01.404727: step 3850, loss = 1.10 (257.9 examples/sec; 0.496 sec/batch)\n",
      "2017-05-06 23:21:06.308594: step 3860, loss = 1.15 (261.0 examples/sec; 0.490 sec/batch)\n",
      "2017-05-06 23:21:11.303031: step 3870, loss = 1.10 (256.3 examples/sec; 0.499 sec/batch)\n",
      "2017-05-06 23:21:16.266585: step 3880, loss = 1.08 (257.9 examples/sec; 0.496 sec/batch)\n",
      "2017-05-06 23:21:21.346725: step 3890, loss = 1.09 (252.0 examples/sec; 0.508 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 2.00595\n",
      "2017-05-06 23:21:26.387662: step 3900, loss = 1.19 (253.9 examples/sec; 0.504 sec/batch)\n",
      "2017-05-06 23:21:31.235376: step 3910, loss = 1.08 (264.0 examples/sec; 0.485 sec/batch)\n",
      "2017-05-06 23:21:36.163826: step 3920, loss = 1.16 (259.7 examples/sec; 0.493 sec/batch)\n",
      "2017-05-06 23:21:41.192403: step 3930, loss = 1.20 (254.5 examples/sec; 0.503 sec/batch)\n",
      "2017-05-06 23:21:46.139474: step 3940, loss = 1.26 (258.7 examples/sec; 0.495 sec/batch)\n",
      "2017-05-06 23:21:51.078842: step 3950, loss = 1.07 (259.1 examples/sec; 0.494 sec/batch)\n",
      "2017-05-06 23:21:55.976749: step 3960, loss = 1.11 (261.3 examples/sec; 0.490 sec/batch)\n",
      "2017-05-06 23:22:00.967338: step 3970, loss = 1.08 (256.5 examples/sec; 0.499 sec/batch)\n",
      "2017-05-06 23:22:05.909539: step 3980, loss = 1.18 (259.0 examples/sec; 0.494 sec/batch)\n",
      "2017-05-06 23:22:10.860332: step 3990, loss = 1.18 (258.5 examples/sec; 0.495 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 2.02044\n",
      "2017-05-06 23:22:15.870851: step 4000, loss = 0.98 (255.5 examples/sec; 0.501 sec/batch)\n",
      "2017-05-06 23:22:20.830607: step 4010, loss = 1.27 (258.1 examples/sec; 0.496 sec/batch)\n",
      "2017-05-06 23:22:25.800951: step 4020, loss = 1.05 (257.5 examples/sec; 0.497 sec/batch)\n",
      "2017-05-06 23:22:30.784282: step 4030, loss = 0.95 (256.9 examples/sec; 0.498 sec/batch)\n",
      "2017-05-06 23:22:35.712264: step 4040, loss = 1.09 (259.7 examples/sec; 0.493 sec/batch)\n",
      "2017-05-06 23:22:40.759782: step 4050, loss = 1.12 (253.6 examples/sec; 0.505 sec/batch)\n",
      "2017-05-06 23:22:45.910815: step 4060, loss = 1.11 (248.5 examples/sec; 0.515 sec/batch)\n",
      "2017-05-06 23:22:50.858036: step 4070, loss = 0.97 (258.7 examples/sec; 0.495 sec/batch)\n",
      "2017-05-06 23:22:55.848727: step 4080, loss = 1.17 (256.5 examples/sec; 0.499 sec/batch)\n",
      "2017-05-06 23:23:00.789167: step 4090, loss = 1.26 (259.1 examples/sec; 0.494 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 2.00296\n",
      "2017-05-06 23:23:05.807819: step 4100, loss = 1.11 (255.0 examples/sec; 0.502 sec/batch)\n",
      "2017-05-06 23:23:10.868765: step 4110, loss = 1.16 (252.9 examples/sec; 0.506 sec/batch)\n",
      "2017-05-06 23:23:16.038928: step 4120, loss = 1.05 (247.6 examples/sec; 0.517 sec/batch)\n",
      "2017-05-06 23:23:22.263548: step 4130, loss = 1.10 (205.6 examples/sec; 0.622 sec/batch)\n",
      "2017-05-06 23:23:28.764644: step 4140, loss = 1.22 (196.9 examples/sec; 0.650 sec/batch)\n",
      "2017-05-06 23:23:34.016527: step 4150, loss = 1.07 (243.7 examples/sec; 0.525 sec/batch)\n",
      "2017-05-06 23:23:40.591345: step 4160, loss = 1.09 (194.7 examples/sec; 0.657 sec/batch)\n",
      "2017-05-06 23:23:46.166036: step 4170, loss = 1.20 (229.6 examples/sec; 0.557 sec/batch)\n",
      "2017-05-06 23:23:51.803087: step 4180, loss = 1.32 (227.1 examples/sec; 0.564 sec/batch)\n",
      "2017-05-06 23:23:56.854510: step 4190, loss = 1.05 (253.4 examples/sec; 0.505 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.77718\n",
      "2017-05-06 23:24:02.071437: step 4200, loss = 0.97 (245.4 examples/sec; 0.522 sec/batch)\n",
      "2017-05-06 23:24:07.757895: step 4210, loss = 1.10 (225.1 examples/sec; 0.569 sec/batch)\n",
      "2017-05-06 23:24:12.878632: step 4220, loss = 1.20 (250.0 examples/sec; 0.512 sec/batch)\n",
      "2017-05-06 23:24:18.808748: step 4230, loss = 1.28 (215.8 examples/sec; 0.593 sec/batch)\n",
      "2017-05-06 23:24:23.829022: step 4240, loss = 1.11 (255.0 examples/sec; 0.502 sec/batch)\n",
      "2017-05-06 23:24:28.804019: step 4250, loss = 1.12 (257.3 examples/sec; 0.497 sec/batch)\n",
      "2017-05-06 23:24:33.665860: step 4260, loss = 1.23 (263.3 examples/sec; 0.486 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-06 23:24:38.644256: step 4270, loss = 1.19 (257.1 examples/sec; 0.498 sec/batch)\n",
      "2017-05-06 23:24:44.360796: step 4280, loss = 0.98 (223.9 examples/sec; 0.572 sec/batch)\n",
      "2017-05-06 23:24:49.784738: step 4290, loss = 1.17 (236.0 examples/sec; 0.542 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.89757\n",
      "2017-05-06 23:24:54.784910: step 4300, loss = 1.33 (256.0 examples/sec; 0.500 sec/batch)\n",
      "2017-05-06 23:24:59.732760: step 4310, loss = 1.08 (258.7 examples/sec; 0.495 sec/batch)\n",
      "2017-05-06 23:25:04.728602: step 4320, loss = 1.00 (256.2 examples/sec; 0.500 sec/batch)\n",
      "2017-05-06 23:25:09.712286: step 4330, loss = 1.20 (256.8 examples/sec; 0.498 sec/batch)\n",
      "2017-05-06 23:25:14.549066: step 4340, loss = 0.92 (264.6 examples/sec; 0.484 sec/batch)\n",
      "2017-05-06 23:25:19.528737: step 4350, loss = 1.07 (257.0 examples/sec; 0.498 sec/batch)\n",
      "2017-05-06 23:25:24.488081: step 4360, loss = 1.04 (258.1 examples/sec; 0.496 sec/batch)\n",
      "2017-05-06 23:25:29.474073: step 4370, loss = 1.17 (256.7 examples/sec; 0.499 sec/batch)\n",
      "2017-05-06 23:25:34.515378: step 4380, loss = 1.11 (253.9 examples/sec; 0.504 sec/batch)\n",
      "2017-05-06 23:25:39.434233: step 4390, loss = 1.05 (260.2 examples/sec; 0.492 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 2.00768\n",
      "2017-05-06 23:25:44.583851: step 4400, loss = 0.97 (248.6 examples/sec; 0.515 sec/batch)\n",
      "2017-05-06 23:25:49.952800: step 4410, loss = 1.11 (238.4 examples/sec; 0.537 sec/batch)\n",
      "2017-05-06 23:25:55.185113: step 4420, loss = 1.17 (244.6 examples/sec; 0.523 sec/batch)\n",
      "2017-05-06 23:26:00.871980: step 4430, loss = 1.05 (225.1 examples/sec; 0.569 sec/batch)\n",
      "2017-05-06 23:26:06.962615: step 4440, loss = 1.16 (210.2 examples/sec; 0.609 sec/batch)\n",
      "2017-05-06 23:26:11.885169: step 4450, loss = 1.20 (260.0 examples/sec; 0.492 sec/batch)\n",
      "2017-05-06 23:26:16.781587: step 4460, loss = 1.10 (261.4 examples/sec; 0.490 sec/batch)\n",
      "2017-05-06 23:26:22.017483: step 4470, loss = 0.88 (244.5 examples/sec; 0.524 sec/batch)\n",
      "2017-05-06 23:26:27.339214: step 4480, loss = 1.08 (240.5 examples/sec; 0.532 sec/batch)\n",
      "2017-05-06 23:26:32.554426: step 4490, loss = 1.14 (245.4 examples/sec; 0.522 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.86732\n",
      "2017-05-06 23:26:38.137507: step 4500, loss = 1.27 (229.3 examples/sec; 0.558 sec/batch)\n",
      "2017-05-06 23:26:43.378032: step 4510, loss = 1.24 (244.3 examples/sec; 0.524 sec/batch)\n",
      "2017-05-06 23:26:48.367578: step 4520, loss = 1.05 (256.5 examples/sec; 0.499 sec/batch)\n",
      "2017-05-06 23:26:53.348898: step 4530, loss = 1.13 (257.0 examples/sec; 0.498 sec/batch)\n",
      "2017-05-06 23:26:58.282851: step 4540, loss = 0.99 (259.4 examples/sec; 0.493 sec/batch)\n",
      "2017-05-06 23:27:03.289321: step 4550, loss = 1.02 (255.7 examples/sec; 0.501 sec/batch)\n",
      "2017-05-06 23:27:08.190897: step 4560, loss = 0.88 (261.1 examples/sec; 0.490 sec/batch)\n",
      "2017-05-06 23:27:13.146817: step 4570, loss = 1.05 (258.3 examples/sec; 0.496 sec/batch)\n",
      "2017-05-06 23:27:18.167883: step 4580, loss = 1.30 (254.9 examples/sec; 0.502 sec/batch)\n",
      "2017-05-06 23:27:22.326398: step 4590, loss = 1.14 (307.8 examples/sec; 0.416 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 2.03168\n",
      "2017-05-06 23:27:27.366497: step 4600, loss = 1.22 (254.0 examples/sec; 0.504 sec/batch)\n",
      "2017-05-06 23:27:32.799468: step 4610, loss = 1.24 (235.6 examples/sec; 0.543 sec/batch)\n",
      "2017-05-06 23:27:38.255019: step 4620, loss = 0.89 (234.6 examples/sec; 0.546 sec/batch)\n",
      "2017-05-06 23:27:43.558331: step 4630, loss = 1.22 (241.4 examples/sec; 0.530 sec/batch)\n",
      "2017-05-06 23:27:49.736543: step 4640, loss = 0.89 (207.2 examples/sec; 0.618 sec/batch)\n",
      "2017-05-06 23:27:55.880693: step 4650, loss = 1.21 (208.3 examples/sec; 0.614 sec/batch)\n",
      "2017-05-06 23:28:02.018901: step 4660, loss = 1.28 (208.5 examples/sec; 0.614 sec/batch)\n",
      "2017-05-06 23:28:07.542456: step 4670, loss = 1.04 (231.7 examples/sec; 0.552 sec/batch)\n",
      "2017-05-06 23:28:13.237650: step 4680, loss = 0.95 (224.8 examples/sec; 0.570 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 4688 into /tmp/cifar10_train_network2/model.ckpt.\n",
      "2017-05-06 23:28:20.146626: step 4690, loss = 1.15 (185.3 examples/sec; 0.691 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.71405\n",
      "2017-05-06 23:28:25.698502: step 4700, loss = 1.09 (230.6 examples/sec; 0.555 sec/batch)\n",
      "2017-05-06 23:28:30.835922: step 4710, loss = 0.96 (249.2 examples/sec; 0.514 sec/batch)\n",
      "2017-05-06 23:28:35.860525: step 4720, loss = 1.06 (254.7 examples/sec; 0.502 sec/batch)\n",
      "2017-05-06 23:28:41.208283: step 4730, loss = 1.13 (239.4 examples/sec; 0.535 sec/batch)\n",
      "2017-05-06 23:28:46.675932: step 4740, loss = 1.22 (234.1 examples/sec; 0.547 sec/batch)\n",
      "2017-05-06 23:28:52.482325: step 4750, loss = 1.07 (220.4 examples/sec; 0.581 sec/batch)\n",
      "2017-05-06 23:28:57.819400: step 4760, loss = 0.97 (239.8 examples/sec; 0.534 sec/batch)\n",
      "2017-05-06 23:29:03.002007: step 4770, loss = 0.87 (247.0 examples/sec; 0.518 sec/batch)\n",
      "2017-05-06 23:29:08.141812: step 4780, loss = 1.05 (249.0 examples/sec; 0.514 sec/batch)\n",
      "2017-05-06 23:29:13.529336: step 4790, loss = 1.04 (237.6 examples/sec; 0.539 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.87595\n",
      "2017-05-06 23:29:19.002049: step 4800, loss = 1.31 (233.9 examples/sec; 0.547 sec/batch)\n",
      "2017-05-06 23:29:24.073951: step 4810, loss = 1.02 (252.4 examples/sec; 0.507 sec/batch)\n",
      "2017-05-06 23:29:29.191442: step 4820, loss = 0.96 (250.1 examples/sec; 0.512 sec/batch)\n",
      "2017-05-06 23:29:34.528033: step 4830, loss = 1.12 (239.9 examples/sec; 0.534 sec/batch)\n",
      "2017-05-06 23:29:39.722553: step 4840, loss = 1.08 (246.4 examples/sec; 0.519 sec/batch)\n",
      "2017-05-06 23:29:44.904211: step 4850, loss = 1.06 (247.0 examples/sec; 0.518 sec/batch)\n",
      "2017-05-06 23:29:49.989137: step 4860, loss = 1.09 (251.7 examples/sec; 0.508 sec/batch)\n",
      "2017-05-06 23:29:55.185769: step 4870, loss = 1.13 (246.3 examples/sec; 0.520 sec/batch)\n",
      "2017-05-06 23:30:00.259359: step 4880, loss = 1.05 (252.3 examples/sec; 0.507 sec/batch)\n",
      "2017-05-06 23:30:05.445827: step 4890, loss = 1.43 (246.8 examples/sec; 0.519 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.94238\n",
      "2017-05-06 23:30:10.480584: step 4900, loss = 1.17 (254.2 examples/sec; 0.503 sec/batch)\n",
      "2017-05-06 23:30:15.536450: step 4910, loss = 1.09 (253.2 examples/sec; 0.506 sec/batch)\n",
      "2017-05-06 23:30:20.498825: step 4920, loss = 1.12 (257.9 examples/sec; 0.496 sec/batch)\n",
      "2017-05-06 23:30:25.501343: step 4930, loss = 1.06 (255.9 examples/sec; 0.500 sec/batch)\n",
      "2017-05-06 23:30:30.566574: step 4940, loss = 1.02 (252.7 examples/sec; 0.507 sec/batch)\n",
      "2017-05-06 23:30:35.649807: step 4950, loss = 1.06 (251.8 examples/sec; 0.508 sec/batch)\n",
      "2017-05-06 23:30:40.640135: step 4960, loss = 1.12 (256.5 examples/sec; 0.499 sec/batch)\n",
      "2017-05-06 23:30:45.790485: step 4970, loss = 1.04 (248.5 examples/sec; 0.515 sec/batch)\n",
      "2017-05-06 23:30:50.794383: step 4980, loss = 1.09 (255.8 examples/sec; 0.500 sec/batch)\n",
      "2017-05-06 23:30:55.716772: step 4990, loss = 1.08 (260.0 examples/sec; 0.492 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.99032\n",
      "2017-05-06 23:31:00.730552: step 5000, loss = 1.04 (255.3 examples/sec; 0.501 sec/batch)\n",
      "2017-05-06 23:31:05.669796: step 5010, loss = 1.11 (259.1 examples/sec; 0.494 sec/batch)\n",
      "2017-05-06 23:31:11.319239: step 5020, loss = 0.96 (226.6 examples/sec; 0.565 sec/batch)\n",
      "2017-05-06 23:31:17.408438: step 5030, loss = 1.02 (210.2 examples/sec; 0.609 sec/batch)\n",
      "2017-05-06 23:31:22.992168: step 5040, loss = 1.14 (229.2 examples/sec; 0.558 sec/batch)\n",
      "2017-05-06 23:31:28.057533: step 5050, loss = 1.27 (252.7 examples/sec; 0.507 sec/batch)\n",
      "2017-05-06 23:31:33.030893: step 5060, loss = 1.13 (257.4 examples/sec; 0.497 sec/batch)\n",
      "2017-05-06 23:31:37.995064: step 5070, loss = 1.20 (257.8 examples/sec; 0.496 sec/batch)\n",
      "2017-05-06 23:31:43.039259: step 5080, loss = 1.08 (253.8 examples/sec; 0.504 sec/batch)\n",
      "2017-05-06 23:31:48.095997: step 5090, loss = 1.25 (253.1 examples/sec; 0.506 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.90732\n",
      "2017-05-06 23:31:53.163222: step 5100, loss = 1.11 (252.6 examples/sec; 0.507 sec/batch)\n",
      "2017-05-06 23:31:58.113697: step 5110, loss = 0.85 (258.6 examples/sec; 0.495 sec/batch)\n",
      "2017-05-06 23:32:03.149810: step 5120, loss = 1.03 (254.2 examples/sec; 0.504 sec/batch)\n",
      "2017-05-06 23:32:08.161876: step 5130, loss = 1.20 (255.4 examples/sec; 0.501 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-06 23:32:13.192896: step 5140, loss = 1.27 (254.4 examples/sec; 0.503 sec/batch)\n",
      "2017-05-06 23:32:18.169334: step 5150, loss = 1.04 (257.2 examples/sec; 0.498 sec/batch)\n",
      "2017-05-06 23:32:23.089212: step 5160, loss = 0.97 (260.2 examples/sec; 0.492 sec/batch)\n",
      "2017-05-06 23:32:28.148880: step 5170, loss = 1.16 (253.0 examples/sec; 0.506 sec/batch)\n",
      "2017-05-06 23:32:33.057481: step 5180, loss = 1.11 (260.8 examples/sec; 0.491 sec/batch)\n",
      "2017-05-06 23:32:38.069241: step 5190, loss = 1.11 (255.4 examples/sec; 0.501 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.99627\n",
      "2017-05-06 23:32:43.253377: step 5200, loss = 1.07 (246.9 examples/sec; 0.518 sec/batch)\n",
      "2017-05-06 23:32:48.358007: step 5210, loss = 1.10 (250.8 examples/sec; 0.510 sec/batch)\n",
      "2017-05-06 23:32:53.277206: step 5220, loss = 0.96 (260.2 examples/sec; 0.492 sec/batch)\n",
      "2017-05-06 23:32:58.181675: step 5230, loss = 0.86 (261.0 examples/sec; 0.490 sec/batch)\n",
      "2017-05-06 23:33:03.186538: step 5240, loss = 1.15 (255.8 examples/sec; 0.500 sec/batch)\n",
      "2017-05-06 23:33:08.197578: step 5250, loss = 1.10 (255.4 examples/sec; 0.501 sec/batch)\n",
      "2017-05-06 23:33:13.129681: step 5260, loss = 0.99 (259.5 examples/sec; 0.493 sec/batch)\n",
      "2017-05-06 23:33:18.060567: step 5270, loss = 1.05 (259.6 examples/sec; 0.493 sec/batch)\n",
      "2017-05-06 23:33:22.942234: step 5280, loss = 1.10 (262.2 examples/sec; 0.488 sec/batch)\n",
      "2017-05-06 23:33:27.905207: step 5290, loss = 0.92 (257.9 examples/sec; 0.496 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 2.00827\n",
      "2017-05-06 23:33:33.052919: step 5300, loss = 0.93 (248.7 examples/sec; 0.515 sec/batch)\n",
      "2017-05-06 23:33:38.105719: step 5310, loss = 1.03 (253.3 examples/sec; 0.505 sec/batch)\n",
      "2017-05-06 23:33:42.998976: step 5320, loss = 1.07 (261.6 examples/sec; 0.489 sec/batch)\n",
      "2017-05-06 23:33:47.967477: step 5330, loss = 0.99 (257.6 examples/sec; 0.497 sec/batch)\n",
      "2017-05-06 23:33:52.955887: step 5340, loss = 1.06 (256.6 examples/sec; 0.499 sec/batch)\n",
      "2017-05-06 23:33:57.875474: step 5350, loss = 1.18 (260.2 examples/sec; 0.492 sec/batch)\n",
      "2017-05-06 23:34:02.878517: step 5360, loss = 1.11 (255.8 examples/sec; 0.500 sec/batch)\n",
      "2017-05-06 23:34:07.918586: step 5370, loss = 1.09 (254.0 examples/sec; 0.504 sec/batch)\n",
      "2017-05-06 23:34:12.883692: step 5380, loss = 1.21 (257.8 examples/sec; 0.497 sec/batch)\n",
      "2017-05-06 23:34:17.878605: step 5390, loss = 0.83 (256.3 examples/sec; 0.499 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 2.00653\n",
      "2017-05-06 23:34:22.889153: step 5400, loss = 1.05 (255.5 examples/sec; 0.501 sec/batch)\n",
      "2017-05-06 23:34:27.795007: step 5410, loss = 0.97 (260.9 examples/sec; 0.491 sec/batch)\n",
      "2017-05-06 23:34:32.797260: step 5420, loss = 1.02 (255.9 examples/sec; 0.500 sec/batch)\n",
      "2017-05-06 23:34:37.743324: step 5430, loss = 1.20 (258.8 examples/sec; 0.495 sec/batch)\n",
      "2017-05-06 23:34:42.721429: step 5440, loss = 1.07 (257.1 examples/sec; 0.498 sec/batch)\n",
      "2017-05-06 23:34:47.727744: step 5450, loss = 1.04 (255.7 examples/sec; 0.501 sec/batch)\n",
      "2017-05-06 23:34:52.655067: step 5460, loss = 0.95 (259.8 examples/sec; 0.493 sec/batch)\n",
      "2017-05-06 23:34:57.644478: step 5470, loss = 0.85 (256.5 examples/sec; 0.499 sec/batch)\n",
      "2017-05-06 23:35:02.602110: step 5480, loss = 1.09 (258.2 examples/sec; 0.496 sec/batch)\n",
      "2017-05-06 23:35:07.607346: step 5490, loss = 1.09 (255.7 examples/sec; 0.501 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 2.00504\n",
      "2017-05-06 23:35:12.766148: step 5500, loss = 1.07 (248.1 examples/sec; 0.516 sec/batch)\n",
      "2017-05-06 23:35:17.736367: step 5510, loss = 1.08 (257.5 examples/sec; 0.497 sec/batch)\n",
      "2017-05-06 23:35:22.740755: step 5520, loss = 1.06 (255.8 examples/sec; 0.500 sec/batch)\n",
      "2017-05-06 23:35:27.669222: step 5530, loss = 1.01 (259.7 examples/sec; 0.493 sec/batch)\n",
      "2017-05-06 23:35:32.658864: step 5540, loss = 1.00 (256.5 examples/sec; 0.499 sec/batch)\n",
      "2017-05-06 23:35:37.679787: step 5550, loss = 1.14 (254.9 examples/sec; 0.502 sec/batch)\n",
      "2017-05-06 23:35:42.813538: step 5560, loss = 1.00 (249.3 examples/sec; 0.513 sec/batch)\n",
      "2017-05-06 23:35:47.905283: step 5570, loss = 1.01 (251.4 examples/sec; 0.509 sec/batch)\n",
      "2017-05-06 23:35:52.826533: step 5580, loss = 1.10 (260.1 examples/sec; 0.492 sec/batch)\n",
      "2017-05-06 23:35:57.730537: step 5590, loss = 1.17 (261.0 examples/sec; 0.490 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 2.0021\n",
      "2017-05-06 23:36:02.707924: step 5600, loss = 1.18 (257.2 examples/sec; 0.498 sec/batch)\n",
      "2017-05-06 23:36:07.688857: step 5610, loss = 1.27 (257.0 examples/sec; 0.498 sec/batch)\n",
      "2017-05-06 23:36:12.744366: step 5620, loss = 1.16 (253.2 examples/sec; 0.506 sec/batch)\n",
      "2017-05-06 23:36:17.723821: step 5630, loss = 0.97 (257.1 examples/sec; 0.498 sec/batch)\n",
      "2017-05-06 23:36:22.666145: step 5640, loss = 1.20 (259.0 examples/sec; 0.494 sec/batch)\n",
      "2017-05-06 23:36:27.555601: step 5650, loss = 0.98 (261.8 examples/sec; 0.489 sec/batch)\n",
      "2017-05-06 23:36:32.468808: step 5660, loss = 1.21 (260.5 examples/sec; 0.491 sec/batch)\n",
      "2017-05-06 23:36:37.494033: step 5670, loss = 1.05 (254.7 examples/sec; 0.503 sec/batch)\n",
      "2017-05-06 23:36:42.404952: step 5680, loss = 0.96 (260.6 examples/sec; 0.491 sec/batch)\n",
      "2017-05-06 23:36:47.527556: step 5690, loss = 1.07 (249.9 examples/sec; 0.512 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 2.00638\n",
      "2017-05-06 23:36:52.560548: step 5700, loss = 1.14 (254.3 examples/sec; 0.503 sec/batch)\n",
      "2017-05-06 23:36:57.540957: step 5710, loss = 0.88 (257.0 examples/sec; 0.498 sec/batch)\n",
      "2017-05-06 23:37:02.442736: step 5720, loss = 1.12 (261.1 examples/sec; 0.490 sec/batch)\n",
      "2017-05-06 23:37:07.471279: step 5730, loss = 1.00 (254.5 examples/sec; 0.503 sec/batch)\n",
      "2017-05-06 23:37:12.454198: step 5740, loss = 0.88 (256.9 examples/sec; 0.498 sec/batch)\n",
      "2017-05-06 23:37:17.446507: step 5750, loss = 1.04 (256.4 examples/sec; 0.499 sec/batch)\n",
      "2017-05-06 23:37:21.552523: step 5760, loss = 1.13 (311.7 examples/sec; 0.411 sec/batch)\n",
      "2017-05-06 23:37:26.583792: step 5770, loss = 1.01 (254.4 examples/sec; 0.503 sec/batch)\n",
      "2017-05-06 23:37:31.538492: step 5780, loss = 0.98 (258.3 examples/sec; 0.495 sec/batch)\n",
      "2017-05-06 23:37:36.564347: step 5790, loss = 0.98 (254.7 examples/sec; 0.503 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 2.038\n",
      "2017-05-06 23:37:41.618328: step 5800, loss = 1.03 (253.3 examples/sec; 0.505 sec/batch)\n",
      "2017-05-06 23:37:46.642487: step 5810, loss = 0.99 (254.8 examples/sec; 0.502 sec/batch)\n",
      "2017-05-06 23:37:51.592807: step 5820, loss = 0.93 (258.6 examples/sec; 0.495 sec/batch)\n",
      "2017-05-06 23:37:56.583563: step 5830, loss = 0.95 (256.5 examples/sec; 0.499 sec/batch)\n",
      "2017-05-06 23:38:01.501098: step 5840, loss = 0.98 (260.3 examples/sec; 0.492 sec/batch)\n",
      "2017-05-06 23:38:06.449348: step 5850, loss = 1.23 (258.7 examples/sec; 0.495 sec/batch)\n",
      "2017-05-06 23:38:11.391885: step 5860, loss = 0.97 (259.0 examples/sec; 0.494 sec/batch)\n",
      "2017-05-06 23:38:16.354654: step 5870, loss = 0.96 (257.9 examples/sec; 0.496 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 5873 into /tmp/cifar10_train_network2/model.ckpt.\n",
      "2017-05-06 23:38:23.050973: step 5880, loss = 1.00 (191.1 examples/sec; 0.670 sec/batch)\n",
      "2017-05-06 23:38:28.060727: step 5890, loss = 1.16 (255.5 examples/sec; 0.501 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.94416\n",
      "2017-05-06 23:38:33.050474: step 5900, loss = 1.01 (256.5 examples/sec; 0.499 sec/batch)\n",
      "2017-05-06 23:38:37.802759: step 5910, loss = 1.00 (269.3 examples/sec; 0.475 sec/batch)\n",
      "2017-05-06 23:38:42.672006: step 5920, loss = 1.06 (262.9 examples/sec; 0.487 sec/batch)\n",
      "2017-05-06 23:38:47.679041: step 5930, loss = 1.11 (255.6 examples/sec; 0.501 sec/batch)\n",
      "2017-05-06 23:38:52.633398: step 5940, loss = 1.05 (258.4 examples/sec; 0.495 sec/batch)\n",
      "2017-05-06 23:38:57.559173: step 5950, loss = 0.94 (259.9 examples/sec; 0.493 sec/batch)\n",
      "2017-05-06 23:39:02.458911: step 5960, loss = 1.15 (261.2 examples/sec; 0.490 sec/batch)\n",
      "2017-05-06 23:39:08.212432: step 5970, loss = 1.06 (222.5 examples/sec; 0.575 sec/batch)\n",
      "2017-05-06 23:39:14.637106: step 5980, loss = 0.96 (199.2 examples/sec; 0.642 sec/batch)\n",
      "2017-05-06 23:39:20.639786: step 5990, loss = 1.05 (213.2 examples/sec; 0.600 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.85088\n",
      "2017-05-06 23:39:27.084518: step 6000, loss = 0.97 (198.6 examples/sec; 0.644 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-06 23:39:32.909531: step 6010, loss = 1.00 (219.7 examples/sec; 0.583 sec/batch)\n",
      "2017-05-06 23:39:38.468066: step 6020, loss = 1.06 (230.3 examples/sec; 0.556 sec/batch)\n",
      "2017-05-06 23:39:43.590108: step 6030, loss = 1.09 (249.9 examples/sec; 0.512 sec/batch)\n",
      "2017-05-06 23:39:48.609365: step 6040, loss = 1.14 (255.0 examples/sec; 0.502 sec/batch)\n",
      "2017-05-06 23:39:53.589861: step 6050, loss = 1.02 (257.0 examples/sec; 0.498 sec/batch)\n",
      "2017-05-06 23:39:58.586424: step 6060, loss = 1.08 (256.2 examples/sec; 0.500 sec/batch)\n",
      "2017-05-06 23:40:03.582286: step 6070, loss = 0.97 (256.2 examples/sec; 0.500 sec/batch)\n",
      "2017-05-06 23:40:08.519711: step 6080, loss = 1.16 (259.2 examples/sec; 0.494 sec/batch)\n",
      "2017-05-06 23:40:13.454294: step 6090, loss = 1.15 (259.4 examples/sec; 0.493 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.94524\n",
      "2017-05-06 23:40:18.520457: step 6100, loss = 1.07 (252.7 examples/sec; 0.507 sec/batch)\n",
      "2017-05-06 23:40:23.522458: step 6110, loss = 0.96 (255.9 examples/sec; 0.500 sec/batch)\n",
      "2017-05-06 23:40:28.440065: step 6120, loss = 1.17 (260.3 examples/sec; 0.492 sec/batch)\n",
      "2017-05-06 23:40:33.472465: step 6130, loss = 1.05 (254.4 examples/sec; 0.503 sec/batch)\n",
      "2017-05-06 23:40:38.498387: step 6140, loss = 0.94 (254.7 examples/sec; 0.503 sec/batch)\n",
      "2017-05-06 23:40:43.502983: step 6150, loss = 1.12 (255.8 examples/sec; 0.500 sec/batch)\n",
      "2017-05-06 23:40:48.509680: step 6160, loss = 0.94 (255.7 examples/sec; 0.501 sec/batch)\n",
      "2017-05-06 23:40:53.506134: step 6170, loss = 0.95 (256.2 examples/sec; 0.500 sec/batch)\n",
      "2017-05-06 23:40:58.447325: step 6180, loss = 1.04 (259.0 examples/sec; 0.494 sec/batch)\n",
      "2017-05-06 23:41:03.460199: step 6190, loss = 1.21 (255.3 examples/sec; 0.501 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.99763\n",
      "2017-05-06 23:41:08.548216: step 6200, loss = 1.11 (251.6 examples/sec; 0.509 sec/batch)\n",
      "2017-05-06 23:41:13.517578: step 6210, loss = 0.95 (257.6 examples/sec; 0.497 sec/batch)\n",
      "2017-05-06 23:41:18.523037: step 6220, loss = 1.11 (255.7 examples/sec; 0.501 sec/batch)\n",
      "2017-05-06 23:41:23.581420: step 6230, loss = 0.87 (253.0 examples/sec; 0.506 sec/batch)\n",
      "2017-05-06 23:41:28.508253: step 6240, loss = 0.95 (259.8 examples/sec; 0.493 sec/batch)\n",
      "2017-05-06 23:41:33.534574: step 6250, loss = 1.09 (254.7 examples/sec; 0.503 sec/batch)\n",
      "2017-05-06 23:41:38.462756: step 6260, loss = 1.09 (259.7 examples/sec; 0.493 sec/batch)\n",
      "2017-05-06 23:41:43.508299: step 6270, loss = 0.90 (253.7 examples/sec; 0.505 sec/batch)\n",
      "2017-05-06 23:41:48.505295: step 6280, loss = 0.96 (256.2 examples/sec; 0.500 sec/batch)\n",
      "2017-05-06 23:41:53.476113: step 6290, loss = 1.29 (257.5 examples/sec; 0.497 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 2.00373\n",
      "2017-05-06 23:41:58.457793: step 6300, loss = 1.09 (256.9 examples/sec; 0.498 sec/batch)\n",
      "2017-05-06 23:42:03.456844: step 6310, loss = 1.21 (256.0 examples/sec; 0.500 sec/batch)\n",
      "2017-05-06 23:42:08.459528: step 6320, loss = 0.95 (255.9 examples/sec; 0.500 sec/batch)\n",
      "2017-05-06 23:42:13.477958: step 6330, loss = 1.01 (255.1 examples/sec; 0.502 sec/batch)\n",
      "2017-05-06 23:42:18.512812: step 6340, loss = 1.00 (254.2 examples/sec; 0.503 sec/batch)\n",
      "2017-05-06 23:42:23.481393: step 6350, loss = 0.93 (257.6 examples/sec; 0.497 sec/batch)\n",
      "2017-05-06 23:42:28.423342: step 6360, loss = 0.96 (259.0 examples/sec; 0.494 sec/batch)\n",
      "2017-05-06 23:42:33.305671: step 6370, loss = 1.34 (262.2 examples/sec; 0.488 sec/batch)\n",
      "2017-05-06 23:42:38.284598: step 6380, loss = 0.93 (257.1 examples/sec; 0.498 sec/batch)\n",
      "2017-05-06 23:42:43.529366: step 6390, loss = 1.18 (244.1 examples/sec; 0.524 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.94598\n",
      "2017-05-06 23:42:49.853983: step 6400, loss = 1.14 (202.4 examples/sec; 0.632 sec/batch)\n",
      "2017-05-06 23:42:55.908823: step 6410, loss = 1.02 (211.4 examples/sec; 0.605 sec/batch)\n",
      "2017-05-06 23:43:01.467760: step 6420, loss = 1.02 (230.3 examples/sec; 0.556 sec/batch)\n",
      "2017-05-06 23:43:06.756612: step 6430, loss = 1.11 (242.0 examples/sec; 0.529 sec/batch)\n",
      "2017-05-06 23:43:12.965827: step 6440, loss = 0.92 (206.1 examples/sec; 0.621 sec/batch)\n",
      "2017-05-06 23:43:18.375140: step 6450, loss = 0.98 (236.6 examples/sec; 0.541 sec/batch)\n",
      "2017-05-06 23:43:23.317225: step 6460, loss = 0.98 (259.0 examples/sec; 0.494 sec/batch)\n",
      "2017-05-06 23:43:28.278938: step 6470, loss = 1.08 (258.0 examples/sec; 0.496 sec/batch)\n",
      "2017-05-06 23:43:33.252403: step 6480, loss = 0.98 (257.4 examples/sec; 0.497 sec/batch)\n",
      "2017-05-06 23:43:38.192177: step 6490, loss = 0.94 (259.1 examples/sec; 0.494 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.86821\n",
      "2017-05-06 23:43:43.383054: step 6500, loss = 0.86 (246.6 examples/sec; 0.519 sec/batch)\n",
      "2017-05-06 23:43:48.310147: step 6510, loss = 1.07 (259.8 examples/sec; 0.493 sec/batch)\n",
      "2017-05-06 23:43:53.304960: step 6520, loss = 1.05 (256.3 examples/sec; 0.499 sec/batch)\n",
      "2017-05-06 23:43:58.295922: step 6530, loss = 1.25 (256.5 examples/sec; 0.499 sec/batch)\n",
      "2017-05-06 23:44:03.199188: step 6540, loss = 1.15 (261.1 examples/sec; 0.490 sec/batch)\n",
      "2017-05-06 23:44:08.220109: step 6550, loss = 1.20 (254.9 examples/sec; 0.502 sec/batch)\n",
      "2017-05-06 23:44:13.254998: step 6560, loss = 1.04 (254.2 examples/sec; 0.503 sec/batch)\n",
      "2017-05-06 23:44:18.274777: step 6570, loss = 1.00 (255.0 examples/sec; 0.502 sec/batch)\n",
      "2017-05-06 23:44:23.251766: step 6580, loss = 0.98 (257.2 examples/sec; 0.498 sec/batch)\n",
      "2017-05-06 23:44:28.184921: step 6590, loss = 0.89 (259.5 examples/sec; 0.493 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.98062\n",
      "2017-05-06 23:44:33.873848: step 6600, loss = 0.97 (225.0 examples/sec; 0.569 sec/batch)\n",
      "2017-05-06 23:44:39.503361: step 6610, loss = 1.17 (227.4 examples/sec; 0.563 sec/batch)\n",
      "2017-05-06 23:44:44.535954: step 6620, loss = 0.90 (254.3 examples/sec; 0.503 sec/batch)\n",
      "2017-05-06 23:44:49.529507: step 6630, loss = 1.10 (256.3 examples/sec; 0.499 sec/batch)\n",
      "2017-05-06 23:44:54.646149: step 6640, loss = 1.17 (250.2 examples/sec; 0.512 sec/batch)\n",
      "2017-05-06 23:44:59.562850: step 6650, loss = 0.93 (260.3 examples/sec; 0.492 sec/batch)\n",
      "2017-05-06 23:45:04.577215: step 6660, loss = 1.20 (255.3 examples/sec; 0.501 sec/batch)\n",
      "2017-05-06 23:45:09.681717: step 6670, loss = 1.31 (250.8 examples/sec; 0.510 sec/batch)\n",
      "2017-05-06 23:45:14.639440: step 6680, loss = 1.02 (258.2 examples/sec; 0.496 sec/batch)\n",
      "2017-05-06 23:45:19.685706: step 6690, loss = 1.00 (253.7 examples/sec; 0.505 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.96624\n",
      "2017-05-06 23:45:24.722215: step 6700, loss = 1.02 (254.1 examples/sec; 0.504 sec/batch)\n",
      "2017-05-06 23:45:29.648336: step 6710, loss = 0.93 (259.8 examples/sec; 0.493 sec/batch)\n",
      "2017-05-06 23:45:34.690586: step 6720, loss = 1.01 (253.9 examples/sec; 0.504 sec/batch)\n",
      "2017-05-06 23:45:39.601018: step 6730, loss = 1.01 (260.7 examples/sec; 0.491 sec/batch)\n",
      "2017-05-06 23:45:44.595553: step 6740, loss = 1.14 (256.3 examples/sec; 0.499 sec/batch)\n",
      "2017-05-06 23:45:49.609281: step 6750, loss = 1.00 (255.3 examples/sec; 0.501 sec/batch)\n",
      "2017-05-06 23:45:54.547816: step 6760, loss = 1.12 (259.2 examples/sec; 0.494 sec/batch)\n",
      "2017-05-06 23:45:59.521165: step 6770, loss = 0.82 (257.4 examples/sec; 0.497 sec/batch)\n",
      "2017-05-06 23:46:04.459638: step 6780, loss = 1.28 (259.2 examples/sec; 0.494 sec/batch)\n",
      "2017-05-06 23:46:09.468325: step 6790, loss = 1.01 (255.6 examples/sec; 0.501 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 2.00647\n",
      "2017-05-06 23:46:14.560361: step 6800, loss = 0.94 (251.4 examples/sec; 0.509 sec/batch)\n",
      "2017-05-06 23:46:19.586094: step 6810, loss = 0.85 (254.7 examples/sec; 0.503 sec/batch)\n",
      "2017-05-06 23:46:24.555476: step 6820, loss = 1.10 (257.6 examples/sec; 0.497 sec/batch)\n",
      "2017-05-06 23:46:29.565191: step 6830, loss = 0.97 (255.5 examples/sec; 0.501 sec/batch)\n",
      "2017-05-06 23:46:34.548288: step 6840, loss = 0.99 (256.9 examples/sec; 0.498 sec/batch)\n",
      "2017-05-06 23:46:39.585911: step 6850, loss = 1.18 (254.1 examples/sec; 0.504 sec/batch)\n",
      "2017-05-06 23:46:44.524457: step 6860, loss = 1.19 (259.2 examples/sec; 0.494 sec/batch)\n",
      "2017-05-06 23:46:49.508282: step 6870, loss = 1.15 (256.8 examples/sec; 0.498 sec/batch)\n",
      "2017-05-06 23:46:54.473493: step 6880, loss = 1.15 (257.8 examples/sec; 0.497 sec/batch)\n",
      "2017-05-06 23:46:59.439899: step 6890, loss = 1.10 (257.7 examples/sec; 0.497 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.00514\n",
      "2017-05-06 23:47:04.426943: step 6900, loss = 0.95 (256.7 examples/sec; 0.499 sec/batch)\n",
      "2017-05-06 23:47:09.636214: step 6910, loss = 1.02 (245.7 examples/sec; 0.521 sec/batch)\n",
      "2017-05-06 23:47:14.602041: step 6920, loss = 0.85 (257.8 examples/sec; 0.497 sec/batch)\n",
      "2017-05-06 23:47:19.619550: step 6930, loss = 1.30 (255.1 examples/sec; 0.502 sec/batch)\n",
      "2017-05-06 23:47:23.662060: step 6940, loss = 1.02 (316.6 examples/sec; 0.404 sec/batch)\n",
      "2017-05-06 23:47:28.570112: step 6950, loss = 1.10 (260.8 examples/sec; 0.491 sec/batch)\n",
      "2017-05-06 23:47:33.494982: step 6960, loss = 1.01 (259.9 examples/sec; 0.492 sec/batch)\n",
      "2017-05-06 23:47:38.504562: step 6970, loss = 0.89 (255.5 examples/sec; 0.501 sec/batch)\n",
      "2017-05-06 23:47:43.465796: step 6980, loss = 1.03 (258.0 examples/sec; 0.496 sec/batch)\n",
      "2017-05-06 23:47:48.595125: step 6990, loss = 1.02 (249.5 examples/sec; 0.513 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 2.03406\n",
      "2017-05-06 23:47:53.597488: step 7000, loss = 0.77 (255.9 examples/sec; 0.500 sec/batch)\n",
      "2017-05-06 23:47:58.526390: step 7010, loss = 1.07 (259.7 examples/sec; 0.493 sec/batch)\n",
      "2017-05-06 23:48:03.456661: step 7020, loss = 1.11 (259.6 examples/sec; 0.493 sec/batch)\n",
      "2017-05-06 23:48:08.394469: step 7030, loss = 0.98 (259.2 examples/sec; 0.494 sec/batch)\n",
      "2017-05-06 23:48:13.396654: step 7040, loss = 1.01 (255.9 examples/sec; 0.500 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 7049 into /tmp/cifar10_train_network2/model.ckpt.\n",
      "2017-05-06 23:48:20.009535: step 7050, loss = 1.02 (193.6 examples/sec; 0.661 sec/batch)\n",
      "2017-05-06 23:48:24.954818: step 7060, loss = 0.96 (258.8 examples/sec; 0.495 sec/batch)\n",
      "2017-05-06 23:48:29.976516: step 7070, loss = 0.92 (254.9 examples/sec; 0.502 sec/batch)\n",
      "2017-05-06 23:48:34.927583: step 7080, loss = 0.84 (258.5 examples/sec; 0.495 sec/batch)\n",
      "2017-05-06 23:48:39.964054: step 7090, loss = 1.00 (254.1 examples/sec; 0.504 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.896\n",
      "2017-05-06 23:48:46.334799: step 7100, loss = 1.02 (200.9 examples/sec; 0.637 sec/batch)\n",
      "2017-05-06 23:48:52.534114: step 7110, loss = 1.01 (206.5 examples/sec; 0.620 sec/batch)\n",
      "2017-05-06 23:48:58.582254: step 7120, loss = 1.06 (211.6 examples/sec; 0.605 sec/batch)\n",
      "2017-05-06 23:49:06.139212: step 7130, loss = 0.97 (169.4 examples/sec; 0.756 sec/batch)\n",
      "2017-05-06 23:49:14.241578: step 7140, loss = 1.00 (158.0 examples/sec; 0.810 sec/batch)\n",
      "2017-05-06 23:49:23.264569: step 7150, loss = 1.19 (141.9 examples/sec; 0.902 sec/batch)\n",
      "2017-05-06 23:49:32.150081: step 7160, loss = 0.87 (144.1 examples/sec; 0.889 sec/batch)\n",
      "2017-05-06 23:49:42.726632: step 7170, loss = 1.21 (121.0 examples/sec; 1.058 sec/batch)\n",
      "2017-05-06 23:49:53.948332: step 7180, loss = 0.99 (114.1 examples/sec; 1.122 sec/batch)\n",
      "2017-05-06 23:50:02.468965: step 7190, loss = 0.88 (150.2 examples/sec; 0.852 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.2142\n",
      "2017-05-06 23:50:08.695369: step 7200, loss = 1.17 (205.6 examples/sec; 0.623 sec/batch)\n",
      "2017-05-06 23:50:17.849582: step 7210, loss = 0.83 (139.8 examples/sec; 0.915 sec/batch)\n",
      "2017-05-06 23:50:26.174455: step 7220, loss = 0.94 (153.8 examples/sec; 0.832 sec/batch)\n",
      "2017-05-06 23:50:33.336989: step 7230, loss = 0.88 (178.7 examples/sec; 0.716 sec/batch)\n",
      "2017-05-06 23:50:38.914457: step 7240, loss = 0.91 (229.5 examples/sec; 0.558 sec/batch)\n",
      "2017-05-06 23:50:44.630905: step 7250, loss = 1.09 (223.9 examples/sec; 0.572 sec/batch)\n",
      "2017-05-06 23:50:52.463593: step 7260, loss = 1.09 (163.4 examples/sec; 0.783 sec/batch)\n",
      "2017-05-06 23:50:57.443326: step 7270, loss = 0.87 (257.0 examples/sec; 0.498 sec/batch)\n",
      "2017-05-06 23:51:03.269460: step 7280, loss = 0.91 (219.7 examples/sec; 0.583 sec/batch)\n",
      "2017-05-06 23:51:08.341716: step 7290, loss = 1.03 (252.4 examples/sec; 0.507 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.52819\n",
      "2017-05-06 23:51:14.129748: step 7300, loss = 1.05 (221.1 examples/sec; 0.579 sec/batch)\n",
      "2017-05-06 23:51:20.051715: step 7310, loss = 0.79 (216.1 examples/sec; 0.592 sec/batch)\n",
      "2017-05-06 23:51:25.620806: step 7320, loss = 0.94 (229.8 examples/sec; 0.557 sec/batch)\n",
      "2017-05-06 23:51:32.100186: step 7330, loss = 1.04 (197.5 examples/sec; 0.648 sec/batch)\n",
      "2017-05-06 23:51:37.749342: step 7340, loss = 0.93 (226.6 examples/sec; 0.565 sec/batch)\n",
      "2017-05-06 23:51:43.452274: step 7350, loss = 1.05 (224.4 examples/sec; 0.570 sec/batch)\n",
      "2017-05-06 23:51:49.391759: step 7360, loss = 1.03 (215.5 examples/sec; 0.594 sec/batch)\n",
      "2017-05-06 23:51:55.477468: step 7370, loss = 1.07 (210.3 examples/sec; 0.609 sec/batch)\n",
      "2017-05-06 23:52:01.418477: step 7380, loss = 1.00 (215.5 examples/sec; 0.594 sec/batch)\n",
      "2017-05-06 23:52:06.505114: step 7390, loss = 1.01 (251.6 examples/sec; 0.509 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.73857\n",
      "2017-05-06 23:52:11.651938: step 7400, loss = 1.00 (248.7 examples/sec; 0.515 sec/batch)\n",
      "2017-05-06 23:52:17.929962: step 7410, loss = 1.08 (203.9 examples/sec; 0.628 sec/batch)\n",
      "2017-05-06 23:52:23.771325: step 7420, loss = 1.09 (219.1 examples/sec; 0.584 sec/batch)\n",
      "2017-05-06 23:52:29.403661: step 7430, loss = 1.13 (227.3 examples/sec; 0.563 sec/batch)\n",
      "2017-05-06 23:52:35.506383: step 7440, loss = 1.09 (209.7 examples/sec; 0.610 sec/batch)\n",
      "2017-05-06 23:52:41.254017: step 7450, loss = 1.04 (222.7 examples/sec; 0.575 sec/batch)\n",
      "2017-05-06 23:52:48.110486: step 7460, loss = 1.03 (186.7 examples/sec; 0.686 sec/batch)\n",
      "2017-05-06 23:52:55.031285: step 7470, loss = 1.09 (184.9 examples/sec; 0.692 sec/batch)\n",
      "2017-05-06 23:53:03.050839: step 7480, loss = 1.06 (159.6 examples/sec; 0.802 sec/batch)\n",
      "2017-05-06 23:53:11.618996: step 7490, loss = 0.93 (149.4 examples/sec; 0.857 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.50999\n",
      "2017-05-06 23:53:17.906206: step 7500, loss = 1.14 (203.6 examples/sec; 0.629 sec/batch)\n",
      "2017-05-06 23:53:27.127813: step 7510, loss = 1.06 (138.8 examples/sec; 0.922 sec/batch)\n",
      "2017-05-06 23:53:35.254506: step 7520, loss = 0.93 (157.5 examples/sec; 0.813 sec/batch)\n",
      "2017-05-06 23:53:40.889935: step 7530, loss = 0.98 (227.1 examples/sec; 0.564 sec/batch)\n",
      "2017-05-06 23:53:50.040933: step 7540, loss = 1.06 (139.9 examples/sec; 0.915 sec/batch)\n",
      "2017-05-06 23:53:57.747614: step 7550, loss = 1.07 (166.1 examples/sec; 0.771 sec/batch)\n",
      "2017-05-06 23:54:03.311307: step 7560, loss = 0.96 (230.1 examples/sec; 0.556 sec/batch)\n",
      "2017-05-06 23:54:08.347966: step 7570, loss = 0.98 (254.1 examples/sec; 0.504 sec/batch)\n",
      "2017-05-06 23:54:13.298026: step 7580, loss = 1.10 (258.6 examples/sec; 0.495 sec/batch)\n",
      "2017-05-06 23:54:18.169312: step 7590, loss = 1.06 (262.8 examples/sec; 0.487 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.52969\n",
      "2017-05-06 23:54:23.242525: step 7600, loss = 1.15 (252.3 examples/sec; 0.507 sec/batch)\n",
      "2017-05-06 23:54:28.170245: step 7610, loss = 1.00 (259.8 examples/sec; 0.493 sec/batch)\n",
      "2017-05-06 23:54:33.086720: step 7620, loss = 0.85 (260.3 examples/sec; 0.492 sec/batch)\n",
      "2017-05-06 23:54:38.097621: step 7630, loss = 1.12 (255.4 examples/sec; 0.501 sec/batch)\n",
      "2017-05-06 23:54:43.485747: step 7640, loss = 0.91 (237.6 examples/sec; 0.539 sec/batch)\n",
      "2017-05-06 23:54:49.860472: step 7650, loss = 1.02 (200.8 examples/sec; 0.637 sec/batch)\n",
      "2017-05-06 23:54:55.886768: step 7660, loss = 1.10 (212.4 examples/sec; 0.603 sec/batch)\n",
      "2017-05-06 23:55:01.642817: step 7670, loss = 1.28 (222.4 examples/sec; 0.576 sec/batch)\n",
      "2017-05-06 23:55:07.042345: step 7680, loss = 0.77 (237.1 examples/sec; 0.540 sec/batch)\n",
      "2017-05-06 23:55:12.253484: step 7690, loss = 0.91 (245.6 examples/sec; 0.521 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.83956\n",
      "2017-05-06 23:55:17.605837: step 7700, loss = 0.87 (239.1 examples/sec; 0.535 sec/batch)\n",
      "2017-05-06 23:55:23.248093: step 7710, loss = 1.03 (226.9 examples/sec; 0.564 sec/batch)\n",
      "2017-05-06 23:55:28.665099: step 7720, loss = 1.08 (236.3 examples/sec; 0.542 sec/batch)\n",
      "2017-05-06 23:55:33.932944: step 7730, loss = 0.96 (243.0 examples/sec; 0.527 sec/batch)\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network_2 evaluating starts...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "eval_dir",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-f3fa0288fa98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-42-5cdb76ad374c>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"network_2 evaluating starts...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mcifar10_eval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mcifar10_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/sedanurdoganay/DeepLearning/CS-466-Project2/cifar10_eval.pyc\u001b[0m in \u001b[0;36mmain\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=unused-argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m   \u001b[0mcifar10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_download_and_extract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDeleteRecursively\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMakeDirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sedanurdoganay/miniconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/platform/flags.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     48\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_flags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__flags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__flags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: eval_dir"
     ]
    }
   ],
   "source": [
    "evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

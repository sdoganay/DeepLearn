{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seda Nur DoÄŸanay - S004299 - Computer Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside input10.py, you can see that L2 Regularization is inserted for avoiding over-fitting.\n",
    "\n",
    "Also in config.py, you can see how the total number of hidden parameters are calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_network1():\n",
    "    \n",
    "    config.train_dir = '/tmp/cifar10_train_network1'\n",
    "    config.eval_dir = '/tmp/cifar10_eval_network1'\n",
    "    config.data_path= '/tmp/cifar10_data'\n",
    "    config.batch_size = 256\n",
    "\n",
    "    #set the parameters for network_1\n",
    "    config.conv1_w_shape = [5, 5, 3, 32]\n",
    "    config.conv1_b_shape = [config.conv1_w_shape[3]]\n",
    "    config.conv1_b = 0.0\n",
    "\n",
    "    # norm1\n",
    "\n",
    "    config.pool1_ksize_shape = [1, 3, 3, 1]\n",
    "    config.pool1_stride_shape = [1, 2, 2, 1]\n",
    "\n",
    "    config.conv2_w_shape = [5, 5, config.conv1_w_shape[3], 16]\n",
    "    config.conv2_b_shape = [config.conv2_w_shape[3]]\n",
    "    config.conv2_b = 0.1\n",
    "\n",
    "    # norm2\n",
    "\n",
    "    config.pool2_ksize_shape = [1, 3, 3, 1]\n",
    "    config.pool2_stride_shape = [1, 2, 2, 1]\n",
    "\n",
    "    config.local3_w_dim = 192\n",
    "    config.local3_w_shape = []  # not directly in my control\n",
    "    config.local3_b_shape = [config.local3_w_dim]\n",
    "    config.local3_b = 0.1\n",
    "\n",
    "    config.local4_w_shape = [config.local3_w_dim, 192/2]\n",
    "    config.local4_b_shape = [config.local4_w_shape[1]]\n",
    "    config.local4_b = 0.1\n",
    "\n",
    "    config.softmax_w_shape = [config.local4_w_shape[1], config.NUM_CLASSES]\n",
    "    config.softmax_b_shape = [config.NUM_CLASSES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initialize_network1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    import cifar10_train\n",
    "    cifar10_train.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    import cifar10_eval\n",
    "    cifar10_eval.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.\n",
      "TRAIN - images shape:  (256, 24, 24, 3) labels shape:  (256,)\n",
      "TRAIN - image e.g. Tensor(\"strided_slice_1:0\", shape=(24, 24, 3), dtype=float32)\n",
      "TRAIN - label e.g. Tensor(\"strided_slice_2:0\", shape=(), dtype=int32)\n",
      "dim 576\n",
      "actual_shape [576, 192]\n",
      "# of hidden parameters 145530  <= 500000\n",
      "INFO:tensorflow:Summary name conv1/weight_loss (raw) is illegal; using conv1/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name conv2/weight_loss (raw) is illegal; using conv2/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name local3/weight_loss (raw) is illegal; using local3/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name local4/weight_loss (raw) is illegal; using local4/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name softmax_linear/weight_loss (raw) is illegal; using softmax_linear/weight_loss__raw_ instead.\n",
      "INFO:tensorflow:Summary name cross_entropy (raw) is illegal; using cross_entropy__raw_ instead.\n",
      "INFO:tensorflow:Summary name total_loss (raw) is illegal; using total_loss__raw_ instead.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/cifar10_train_network1/model.ckpt.\n",
      "2017-05-06 22:47:18.371639: step 0, loss = 2.62 (280.4 examples/sec; 0.913 sec/batch)\n",
      "2017-05-06 22:47:23.128853: step 10, loss = 2.62 (538.1 examples/sec; 0.476 sec/batch)\n",
      "2017-05-06 22:47:28.105790: step 20, loss = 2.62 (514.4 examples/sec; 0.498 sec/batch)\n",
      "2017-05-06 22:47:32.809458: step 30, loss = 2.61 (544.3 examples/sec; 0.470 sec/batch)\n",
      "2017-05-06 22:47:37.489945: step 40, loss = 2.61 (547.0 examples/sec; 0.468 sec/batch)\n",
      "2017-05-06 22:47:42.713944: step 50, loss = 2.60 (490.0 examples/sec; 0.522 sec/batch)\n",
      "2017-05-06 22:47:48.312429: step 60, loss = 2.59 (457.3 examples/sec; 0.560 sec/batch)\n",
      "2017-05-06 22:47:53.253389: step 70, loss = 2.55 (518.1 examples/sec; 0.494 sec/batch)\n",
      "2017-05-06 22:47:58.814218: step 80, loss = 2.49 (460.4 examples/sec; 0.556 sec/batch)\n",
      "2017-05-06 22:48:04.266589: step 90, loss = 2.44 (469.5 examples/sec; 0.545 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.82817\n",
      "2017-05-06 22:48:12.409930: step 100, loss = 2.44 (314.8 examples/sec; 0.813 sec/batch)\n",
      "2017-05-06 22:48:18.828387: step 110, loss = 2.35 (398.2 examples/sec; 0.643 sec/batch)\n",
      "2017-05-06 22:48:27.316890: step 120, loss = 2.32 (301.6 examples/sec; 0.849 sec/batch)\n",
      "2017-05-06 22:48:35.880190: step 130, loss = 2.29 (299.0 examples/sec; 0.856 sec/batch)\n",
      "2017-05-06 22:48:44.073882: step 140, loss = 2.41 (312.4 examples/sec; 0.819 sec/batch)\n",
      "2017-05-06 22:48:52.522341: step 150, loss = 2.37 (303.0 examples/sec; 0.845 sec/batch)\n",
      "2017-05-06 22:49:01.820279: step 160, loss = 2.28 (275.3 examples/sec; 0.930 sec/batch)\n",
      "2017-05-06 22:49:10.502299: step 170, loss = 2.33 (294.9 examples/sec; 0.868 sec/batch)\n",
      "2017-05-06 22:49:19.185195: step 180, loss = 2.18 (294.8 examples/sec; 0.868 sec/batch)\n",
      "2017-05-06 22:49:27.704285: step 190, loss = 2.20 (300.5 examples/sec; 0.852 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.18374\n",
      "2017-05-06 22:49:36.893953: step 200, loss = 2.12 (278.6 examples/sec; 0.919 sec/batch)\n",
      "2017-05-06 22:49:45.154235: step 210, loss = 2.12 (309.9 examples/sec; 0.826 sec/batch)\n",
      "2017-05-06 22:49:53.209523: step 220, loss = 2.16 (317.8 examples/sec; 0.806 sec/batch)\n",
      "2017-05-06 22:50:01.323505: step 230, loss = 2.14 (315.5 examples/sec; 0.811 sec/batch)\n",
      "2017-05-06 22:50:09.524588: step 240, loss = 2.13 (312.2 examples/sec; 0.820 sec/batch)\n",
      "2017-05-06 22:50:17.612051: step 250, loss = 1.98 (316.5 examples/sec; 0.809 sec/batch)\n",
      "2017-05-06 22:50:25.684192: step 260, loss = 2.11 (317.1 examples/sec; 0.807 sec/batch)\n",
      "2017-05-06 22:50:33.948790: step 270, loss = 2.25 (309.8 examples/sec; 0.826 sec/batch)\n",
      "2017-05-06 22:50:41.925411: step 280, loss = 2.06 (320.9 examples/sec; 0.798 sec/batch)\n",
      "2017-05-06 22:50:49.981686: step 290, loss = 2.00 (317.8 examples/sec; 0.806 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.22858\n",
      "2017-05-06 22:50:58.290211: step 300, loss = 2.22 (308.1 examples/sec; 0.831 sec/batch)\n",
      "2017-05-06 22:51:06.423667: step 310, loss = 2.03 (314.7 examples/sec; 0.813 sec/batch)\n",
      "2017-05-06 22:51:14.447482: step 320, loss = 2.10 (319.0 examples/sec; 0.802 sec/batch)\n",
      "2017-05-06 22:51:22.614148: step 330, loss = 2.08 (313.5 examples/sec; 0.817 sec/batch)\n",
      "2017-05-06 22:51:30.848044: step 340, loss = 2.18 (310.9 examples/sec; 0.823 sec/batch)\n",
      "2017-05-06 22:51:38.878488: step 350, loss = 1.95 (318.8 examples/sec; 0.803 sec/batch)\n",
      "2017-05-06 22:51:47.163775: step 360, loss = 2.07 (309.0 examples/sec; 0.829 sec/batch)\n",
      "2017-05-06 22:51:55.203471: step 370, loss = 1.95 (318.4 examples/sec; 0.804 sec/batch)\n",
      "2017-05-06 22:52:03.293980: step 380, loss = 2.01 (316.4 examples/sec; 0.809 sec/batch)\n",
      "2017-05-06 22:52:11.466486: step 390, loss = 2.05 (313.2 examples/sec; 0.817 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.22869\n",
      "2017-05-06 22:52:19.674877: step 400, loss = 1.96 (311.9 examples/sec; 0.821 sec/batch)\n",
      "2017-05-06 22:52:27.737259: step 410, loss = 1.96 (317.5 examples/sec; 0.806 sec/batch)\n",
      "2017-05-06 22:52:36.041903: step 420, loss = 1.92 (308.3 examples/sec; 0.830 sec/batch)\n",
      "2017-05-06 22:52:44.161517: step 430, loss = 1.99 (315.3 examples/sec; 0.812 sec/batch)\n",
      "2017-05-06 22:52:52.846723: step 440, loss = 2.07 (294.8 examples/sec; 0.869 sec/batch)\n",
      "2017-05-06 22:53:00.996649: step 450, loss = 1.95 (314.1 examples/sec; 0.815 sec/batch)\n",
      "2017-05-06 22:53:09.481674: step 460, loss = 1.81 (301.7 examples/sec; 0.849 sec/batch)\n",
      "2017-05-06 22:53:19.400987: step 470, loss = 1.89 (258.1 examples/sec; 0.992 sec/batch)\n",
      "2017-05-06 22:53:28.805225: step 480, loss = 1.84 (272.2 examples/sec; 0.940 sec/batch)\n",
      "2017-05-06 22:53:38.430979: step 490, loss = 1.90 (266.0 examples/sec; 0.963 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14896\n",
      "2017-05-06 22:53:46.712846: step 500, loss = 1.96 (309.1 examples/sec; 0.828 sec/batch)\n",
      "2017-05-06 22:53:54.789841: step 510, loss = 1.80 (316.9 examples/sec; 0.808 sec/batch)\n",
      "2017-05-06 22:54:02.937356: step 520, loss = 1.86 (314.2 examples/sec; 0.815 sec/batch)\n",
      "2017-05-06 22:54:11.431271: step 530, loss = 1.87 (301.4 examples/sec; 0.849 sec/batch)\n",
      "2017-05-06 22:54:20.427799: step 540, loss = 1.95 (284.6 examples/sec; 0.900 sec/batch)\n",
      "2017-05-06 22:54:28.846338: step 550, loss = 1.87 (304.1 examples/sec; 0.842 sec/batch)\n",
      "2017-05-06 22:54:37.187332: step 560, loss = 1.86 (306.9 examples/sec; 0.834 sec/batch)\n",
      "2017-05-06 22:54:45.699162: step 570, loss = 1.91 (300.8 examples/sec; 0.851 sec/batch)\n",
      "2017-05-06 22:54:55.247472: step 580, loss = 1.83 (268.1 examples/sec; 0.955 sec/batch)\n",
      "2017-05-06 22:55:05.667912: step 590, loss = 1.81 (245.7 examples/sec; 1.042 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.14452\n",
      "2017-05-06 22:55:14.079221: step 600, loss = 1.85 (304.4 examples/sec; 0.841 sec/batch)\n",
      "2017-05-06 22:55:22.184080: step 610, loss = 1.68 (315.9 examples/sec; 0.810 sec/batch)\n",
      "2017-05-06 22:55:30.298729: step 620, loss = 1.83 (315.5 examples/sec; 0.811 sec/batch)\n",
      "2017-05-06 22:55:38.432886: step 630, loss = 1.75 (314.7 examples/sec; 0.813 sec/batch)\n",
      "2017-05-06 22:55:46.505319: step 640, loss = 1.69 (317.1 examples/sec; 0.807 sec/batch)\n",
      "2017-05-06 22:55:54.530551: step 650, loss = 1.93 (319.0 examples/sec; 0.803 sec/batch)\n",
      "2017-05-06 22:56:02.615748: step 660, loss = 1.74 (316.6 examples/sec; 0.809 sec/batch)\n",
      "2017-05-06 22:56:10.744466: step 670, loss = 1.76 (314.9 examples/sec; 0.813 sec/batch)\n",
      "2017-05-06 22:56:18.765126: step 680, loss = 1.78 (319.2 examples/sec; 0.802 sec/batch)\n",
      "2017-05-06 22:56:26.774494: step 690, loss = 1.82 (319.6 examples/sec; 0.801 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.23527\n",
      "2017-05-06 22:56:35.039686: step 700, loss = 1.79 (309.7 examples/sec; 0.827 sec/batch)\n",
      "2017-05-06 22:56:43.105923: step 710, loss = 1.72 (317.4 examples/sec; 0.807 sec/batch)\n",
      "2017-05-06 22:56:51.058903: step 720, loss = 1.79 (321.9 examples/sec; 0.795 sec/batch)\n",
      "2017-05-06 22:56:59.239417: step 730, loss = 1.79 (312.9 examples/sec; 0.818 sec/batch)\n",
      "2017-05-06 22:57:07.410103: step 740, loss = 1.74 (313.3 examples/sec; 0.817 sec/batch)\n",
      "2017-05-06 22:57:15.433815: step 750, loss = 1.74 (319.1 examples/sec; 0.802 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 754 into /tmp/cifar10_train_network1/model.ckpt.\n",
      "2017-05-06 22:57:25.194791: step 760, loss = 1.86 (262.3 examples/sec; 0.976 sec/batch)\n",
      "2017-05-06 22:57:33.352778: step 770, loss = 1.76 (313.8 examples/sec; 0.816 sec/batch)\n",
      "2017-05-06 22:57:41.381311: step 780, loss = 1.90 (318.9 examples/sec; 0.803 sec/batch)\n",
      "2017-05-06 22:57:49.657248: step 790, loss = 1.78 (309.3 examples/sec; 0.828 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.20749\n",
      "2017-05-06 22:57:57.849371: step 800, loss = 1.78 (312.5 examples/sec; 0.819 sec/batch)\n",
      "2017-05-06 22:58:05.952361: step 810, loss = 1.71 (315.9 examples/sec; 0.810 sec/batch)\n",
      "2017-05-06 22:58:14.028139: step 820, loss = 2.14 (317.0 examples/sec; 0.808 sec/batch)\n",
      "2017-05-06 22:58:21.361626: step 830, loss = 1.70 (349.1 examples/sec; 0.733 sec/batch)\n",
      "2017-05-06 22:58:29.445706: step 840, loss = 1.74 (316.7 examples/sec; 0.808 sec/batch)\n",
      "2017-05-06 22:58:37.607475: step 850, loss = 1.61 (313.7 examples/sec; 0.816 sec/batch)\n",
      "2017-05-06 22:58:45.660581: step 860, loss = 1.51 (317.9 examples/sec; 0.805 sec/batch)\n",
      "2017-05-06 22:58:53.724657: step 870, loss = 1.90 (317.5 examples/sec; 0.806 sec/batch)\n",
      "2017-05-06 22:59:01.896437: step 880, loss = 1.75 (313.3 examples/sec; 0.817 sec/batch)\n",
      "2017-05-06 22:59:10.012620: step 890, loss = 1.65 (315.4 examples/sec; 0.812 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.24677\n",
      "2017-05-06 22:59:18.053838: step 900, loss = 1.62 (318.4 examples/sec; 0.804 sec/batch)\n",
      "2017-05-06 22:59:26.131917: step 910, loss = 1.75 (316.9 examples/sec; 0.808 sec/batch)\n",
      "2017-05-06 22:59:34.179312: step 920, loss = 1.78 (318.1 examples/sec; 0.805 sec/batch)\n",
      "2017-05-06 22:59:42.297637: step 930, loss = 1.57 (315.3 examples/sec; 0.812 sec/batch)\n",
      "2017-05-06 22:59:50.395719: step 940, loss = 1.59 (316.1 examples/sec; 0.810 sec/batch)\n",
      "2017-05-06 22:59:58.449124: step 950, loss = 1.72 (317.9 examples/sec; 0.805 sec/batch)\n",
      "2017-05-06 23:00:06.418308: step 960, loss = 1.67 (321.2 examples/sec; 0.797 sec/batch)\n",
      "2017-05-06 23:00:14.472353: step 970, loss = 1.53 (317.9 examples/sec; 0.805 sec/batch)\n",
      "2017-05-06 23:00:22.503273: step 980, loss = 1.58 (318.8 examples/sec; 0.803 sec/batch)\n",
      "2017-05-06 23:00:30.562018: step 990, loss = 1.57 (317.7 examples/sec; 0.806 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.23997\n",
      "2017-05-06 23:00:38.704612: step 1000, loss = 1.83 (314.4 examples/sec; 0.814 sec/batch)\n",
      "2017-05-06 23:00:46.741414: step 1010, loss = 1.57 (318.5 examples/sec; 0.804 sec/batch)\n",
      "2017-05-06 23:00:54.749478: step 1020, loss = 1.63 (319.7 examples/sec; 0.801 sec/batch)\n",
      "2017-05-06 23:01:02.911283: step 1030, loss = 1.61 (313.7 examples/sec; 0.816 sec/batch)\n",
      "2017-05-06 23:01:11.022470: step 1040, loss = 1.59 (315.6 examples/sec; 0.811 sec/batch)\n",
      "2017-05-06 23:01:19.107120: step 1050, loss = 1.54 (316.6 examples/sec; 0.808 sec/batch)\n",
      "2017-05-06 23:01:27.126436: step 1060, loss = 1.83 (319.2 examples/sec; 0.802 sec/batch)\n",
      "2017-05-06 23:01:35.295739: step 1070, loss = 1.67 (313.4 examples/sec; 0.817 sec/batch)\n",
      "2017-05-06 23:01:43.418304: step 1080, loss = 1.74 (315.2 examples/sec; 0.812 sec/batch)\n",
      "2017-05-06 23:01:51.495047: step 1090, loss = 1.65 (317.0 examples/sec; 0.808 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.23661\n",
      "2017-05-06 23:01:59.569691: step 1100, loss = 1.65 (317.0 examples/sec; 0.807 sec/batch)\n",
      "2017-05-06 23:02:07.696455: step 1110, loss = 1.60 (315.0 examples/sec; 0.813 sec/batch)\n",
      "2017-05-06 23:02:15.783817: step 1120, loss = 1.56 (316.5 examples/sec; 0.809 sec/batch)\n",
      "2017-05-06 23:02:23.850538: step 1130, loss = 1.72 (317.4 examples/sec; 0.807 sec/batch)\n",
      "2017-05-06 23:02:31.874272: step 1140, loss = 1.54 (319.1 examples/sec; 0.802 sec/batch)\n",
      "2017-05-06 23:02:39.936838: step 1150, loss = 1.56 (317.5 examples/sec; 0.806 sec/batch)\n",
      "2017-05-06 23:02:47.981093: step 1160, loss = 1.48 (318.2 examples/sec; 0.804 sec/batch)\n",
      "2017-05-06 23:02:55.968606: step 1170, loss = 1.67 (320.5 examples/sec; 0.799 sec/batch)\n",
      "2017-05-06 23:03:04.121838: step 1180, loss = 1.53 (314.0 examples/sec; 0.815 sec/batch)\n",
      "2017-05-06 23:03:12.306754: step 1190, loss = 1.70 (312.8 examples/sec; 0.818 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.23672\n",
      "2017-05-06 23:03:20.443832: step 1200, loss = 1.55 (314.6 examples/sec; 0.814 sec/batch)\n",
      "2017-05-06 23:03:28.364411: step 1210, loss = 1.73 (323.2 examples/sec; 0.792 sec/batch)\n",
      "2017-05-06 23:03:36.448227: step 1220, loss = 1.62 (316.7 examples/sec; 0.808 sec/batch)\n",
      "2017-05-06 23:03:44.518482: step 1230, loss = 1.78 (317.2 examples/sec; 0.807 sec/batch)\n",
      "2017-05-06 23:03:52.539103: step 1240, loss = 1.55 (319.2 examples/sec; 0.802 sec/batch)\n",
      "2017-05-06 23:04:01.456963: step 1250, loss = 1.52 (287.1 examples/sec; 0.892 sec/batch)\n",
      "2017-05-06 23:04:11.471724: step 1260, loss = 1.67 (255.6 examples/sec; 1.001 sec/batch)\n",
      "2017-05-06 23:04:20.214433: step 1270, loss = 1.45 (292.8 examples/sec; 0.874 sec/batch)\n",
      "2017-05-06 23:04:28.396377: step 1280, loss = 1.51 (312.9 examples/sec; 0.818 sec/batch)\n",
      "2017-05-06 23:04:36.555784: step 1290, loss = 1.58 (313.7 examples/sec; 0.816 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.18588\n",
      "2017-05-06 23:04:44.753164: step 1300, loss = 1.70 (312.3 examples/sec; 0.820 sec/batch)\n",
      "2017-05-06 23:04:52.804345: step 1310, loss = 1.74 (318.0 examples/sec; 0.805 sec/batch)\n",
      "2017-05-06 23:05:00.854135: step 1320, loss = 1.50 (318.0 examples/sec; 0.805 sec/batch)\n",
      "2017-05-06 23:05:09.119726: step 1330, loss = 1.61 (309.7 examples/sec; 0.827 sec/batch)\n",
      "2017-05-06 23:05:17.181671: step 1340, loss = 1.56 (317.5 examples/sec; 0.806 sec/batch)\n",
      "2017-05-06 23:05:25.199770: step 1350, loss = 1.69 (319.3 examples/sec; 0.802 sec/batch)\n",
      "2017-05-06 23:05:33.298235: step 1360, loss = 1.50 (316.1 examples/sec; 0.810 sec/batch)\n",
      "2017-05-06 23:05:41.480857: step 1370, loss = 1.46 (312.9 examples/sec; 0.818 sec/batch)\n",
      "2017-05-06 23:05:49.548314: step 1380, loss = 1.61 (317.3 examples/sec; 0.807 sec/batch)\n",
      "2017-05-06 23:05:57.613270: step 1390, loss = 1.55 (317.4 examples/sec; 0.806 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.23124\n",
      "2017-05-06 23:06:05.981169: step 1400, loss = 1.81 (305.9 examples/sec; 0.837 sec/batch)\n",
      "2017-05-06 23:06:14.174073: step 1410, loss = 1.39 (312.5 examples/sec; 0.819 sec/batch)\n",
      "2017-05-06 23:06:22.205957: step 1420, loss = 1.40 (318.7 examples/sec; 0.803 sec/batch)\n",
      "2017-05-06 23:06:30.252302: step 1430, loss = 1.51 (318.2 examples/sec; 0.805 sec/batch)\n",
      "2017-05-06 23:06:38.356340: step 1440, loss = 1.40 (315.9 examples/sec; 0.810 sec/batch)\n",
      "2017-05-06 23:06:46.386493: step 1450, loss = 1.76 (318.8 examples/sec; 0.803 sec/batch)\n",
      "2017-05-06 23:06:54.392647: step 1460, loss = 1.53 (319.8 examples/sec; 0.801 sec/batch)\n",
      "2017-05-06 23:07:02.564242: step 1470, loss = 1.56 (313.3 examples/sec; 0.817 sec/batch)\n",
      "2017-05-06 23:07:10.791747: step 1480, loss = 1.68 (311.2 examples/sec; 0.823 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 1490 into /tmp/cifar10_train_network1/model.ckpt.\n",
      "2017-05-06 23:07:20.286333: step 1490, loss = 1.50 (269.6 examples/sec; 0.949 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.21227\n",
      "2017-05-06 23:07:28.469222: step 1500, loss = 1.59 (312.8 examples/sec; 0.818 sec/batch)\n",
      "2017-05-06 23:07:36.580595: step 1510, loss = 1.49 (315.6 examples/sec; 0.811 sec/batch)\n",
      "2017-05-06 23:07:44.566799: step 1520, loss = 1.35 (320.6 examples/sec; 0.799 sec/batch)\n",
      "2017-05-06 23:07:52.786198: step 1530, loss = 1.38 (311.5 examples/sec; 0.822 sec/batch)\n",
      "2017-05-06 23:08:00.842333: step 1540, loss = 1.54 (317.8 examples/sec; 0.806 sec/batch)\n",
      "2017-05-06 23:08:08.962195: step 1550, loss = 1.35 (315.3 examples/sec; 0.812 sec/batch)\n",
      "2017-05-06 23:08:16.909259: step 1560, loss = 1.53 (322.1 examples/sec; 0.795 sec/batch)\n",
      "2017-05-06 23:08:24.550824: step 1570, loss = 1.44 (335.0 examples/sec; 0.764 sec/batch)\n",
      "2017-05-06 23:08:32.550713: step 1580, loss = 1.27 (320.0 examples/sec; 0.800 sec/batch)\n",
      "2017-05-06 23:08:42.021848: step 1590, loss = 1.42 (270.3 examples/sec; 0.947 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.2009\n",
      "2017-05-06 23:08:51.737063: step 1600, loss = 1.35 (263.5 examples/sec; 0.972 sec/batch)\n",
      "2017-05-06 23:09:00.347681: step 1610, loss = 1.49 (297.3 examples/sec; 0.861 sec/batch)\n",
      "2017-05-06 23:09:08.965708: step 1620, loss = 1.38 (297.1 examples/sec; 0.862 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-06 23:09:17.981366: step 1630, loss = 1.34 (283.9 examples/sec; 0.902 sec/batch)\n",
      "2017-05-06 23:09:26.790364: step 1640, loss = 1.42 (290.6 examples/sec; 0.881 sec/batch)\n",
      "2017-05-06 23:09:35.391775: step 1650, loss = 1.33 (297.6 examples/sec; 0.860 sec/batch)\n",
      "2017-05-06 23:09:43.831164: step 1660, loss = 1.42 (303.3 examples/sec; 0.844 sec/batch)\n",
      "2017-05-06 23:09:52.186247: step 1670, loss = 1.42 (306.4 examples/sec; 0.836 sec/batch)\n",
      "2017-05-06 23:10:00.917778: step 1680, loss = 1.48 (293.2 examples/sec; 0.873 sec/batch)\n",
      "2017-05-06 23:10:09.241051: step 1690, loss = 1.40 (307.6 examples/sec; 0.832 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.16458\n",
      "2017-05-06 23:10:17.629040: step 1700, loss = 1.37 (305.2 examples/sec; 0.839 sec/batch)\n",
      "2017-05-06 23:10:26.130483: step 1710, loss = 1.59 (301.1 examples/sec; 0.850 sec/batch)\n",
      "2017-05-06 23:10:35.974424: step 1720, loss = 1.53 (260.1 examples/sec; 0.984 sec/batch)\n",
      "2017-05-06 23:10:45.839111: step 1730, loss = 1.43 (259.5 examples/sec; 0.986 sec/batch)\n",
      "2017-05-06 23:10:53.880399: step 1740, loss = 1.37 (318.4 examples/sec; 0.804 sec/batch)\n",
      "2017-05-06 23:11:01.985726: step 1750, loss = 1.25 (315.8 examples/sec; 0.811 sec/batch)\n",
      "2017-05-06 23:11:10.148746: step 1760, loss = 1.30 (313.6 examples/sec; 0.816 sec/batch)\n",
      "2017-05-06 23:11:18.341090: step 1770, loss = 1.32 (312.5 examples/sec; 0.819 sec/batch)\n",
      "2017-05-06 23:11:26.503065: step 1780, loss = 1.33 (313.6 examples/sec; 0.816 sec/batch)\n",
      "2017-05-06 23:11:34.524456: step 1790, loss = 1.43 (319.1 examples/sec; 0.802 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.17458\n",
      "2017-05-06 23:11:42.743458: step 1800, loss = 1.55 (311.5 examples/sec; 0.822 sec/batch)\n",
      "2017-05-06 23:11:50.727855: step 1810, loss = 1.31 (320.6 examples/sec; 0.798 sec/batch)\n",
      "2017-05-06 23:11:58.742583: step 1820, loss = 1.38 (319.4 examples/sec; 0.801 sec/batch)\n",
      "2017-05-06 23:12:06.746979: step 1830, loss = 1.26 (319.8 examples/sec; 0.800 sec/batch)\n",
      "2017-05-06 23:12:15.016381: step 1840, loss = 1.43 (309.6 examples/sec; 0.827 sec/batch)\n",
      "2017-05-06 23:12:22.997957: step 1850, loss = 1.41 (320.7 examples/sec; 0.798 sec/batch)\n",
      "2017-05-06 23:12:31.029286: step 1860, loss = 1.35 (318.8 examples/sec; 0.803 sec/batch)\n",
      "2017-05-06 23:12:39.187298: step 1870, loss = 1.23 (313.8 examples/sec; 0.816 sec/batch)\n",
      "2017-05-06 23:12:47.189370: step 1880, loss = 1.49 (319.9 examples/sec; 0.800 sec/batch)\n",
      "2017-05-06 23:12:55.322371: step 1890, loss = 1.25 (314.8 examples/sec; 0.813 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.2379\n",
      "2017-05-06 23:13:03.516578: step 1900, loss = 1.28 (312.4 examples/sec; 0.819 sec/batch)\n",
      "2017-05-06 23:13:11.714255: step 1910, loss = 1.39 (312.3 examples/sec; 0.820 sec/batch)\n",
      "2017-05-06 23:13:19.844381: step 1920, loss = 1.26 (314.9 examples/sec; 0.813 sec/batch)\n",
      "2017-05-06 23:13:27.991044: step 1930, loss = 1.40 (314.2 examples/sec; 0.815 sec/batch)\n",
      "2017-05-06 23:13:36.127087: step 1940, loss = 1.38 (314.6 examples/sec; 0.814 sec/batch)\n",
      "2017-05-06 23:13:44.364677: step 1950, loss = 1.26 (310.8 examples/sec; 0.824 sec/batch)\n",
      "2017-05-06 23:13:52.501218: step 1960, loss = 1.36 (314.6 examples/sec; 0.814 sec/batch)\n",
      "2017-05-06 23:14:00.654193: step 1970, loss = 1.33 (314.0 examples/sec; 0.815 sec/batch)\n",
      "2017-05-06 23:14:08.673131: step 1980, loss = 1.39 (319.2 examples/sec; 0.802 sec/batch)\n",
      "2017-05-06 23:14:16.767949: step 1990, loss = 1.28 (316.3 examples/sec; 0.809 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.22933\n",
      "2017-05-06 23:14:24.874483: step 2000, loss = 1.33 (315.8 examples/sec; 0.811 sec/batch)\n",
      "2017-05-06 23:14:32.933138: step 2010, loss = 1.19 (317.7 examples/sec; 0.806 sec/batch)\n",
      "2017-05-06 23:14:41.221404: step 2020, loss = 1.47 (308.9 examples/sec; 0.829 sec/batch)\n",
      "2017-05-06 23:14:49.142951: step 2030, loss = 1.35 (323.2 examples/sec; 0.792 sec/batch)\n",
      "2017-05-06 23:14:57.277053: step 2040, loss = 1.23 (314.7 examples/sec; 0.813 sec/batch)\n",
      "2017-05-06 23:15:05.349026: step 2050, loss = 1.33 (317.1 examples/sec; 0.807 sec/batch)\n",
      "2017-05-06 23:15:13.394749: step 2060, loss = 1.53 (318.2 examples/sec; 0.805 sec/batch)\n",
      "2017-05-06 23:15:21.557431: step 2070, loss = 1.23 (313.6 examples/sec; 0.816 sec/batch)\n",
      "2017-05-06 23:15:29.618275: step 2080, loss = 1.35 (317.6 examples/sec; 0.806 sec/batch)\n",
      "2017-05-06 23:15:37.636099: step 2090, loss = 1.25 (319.3 examples/sec; 0.802 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.23541\n",
      "2017-05-06 23:15:45.809982: step 2100, loss = 1.37 (313.2 examples/sec; 0.817 sec/batch)\n",
      "2017-05-06 23:15:53.789260: step 2110, loss = 1.41 (320.8 examples/sec; 0.798 sec/batch)\n",
      "2017-05-06 23:16:01.845655: step 2120, loss = 1.23 (317.8 examples/sec; 0.806 sec/batch)\n",
      "2017-05-06 23:16:10.012643: step 2130, loss = 1.18 (313.5 examples/sec; 0.817 sec/batch)\n",
      "2017-05-06 23:16:18.187781: step 2140, loss = 1.18 (313.1 examples/sec; 0.818 sec/batch)\n",
      "2017-05-06 23:16:26.276077: step 2150, loss = 1.24 (316.5 examples/sec; 0.809 sec/batch)\n",
      "2017-05-06 23:16:34.475690: step 2160, loss = 1.29 (312.2 examples/sec; 0.820 sec/batch)\n",
      "2017-05-06 23:16:42.667174: step 2170, loss = 1.15 (312.5 examples/sec; 0.819 sec/batch)\n",
      "2017-05-06 23:16:50.787267: step 2180, loss = 1.37 (315.3 examples/sec; 0.812 sec/batch)\n",
      "2017-05-06 23:16:58.798752: step 2190, loss = 1.31 (319.5 examples/sec; 0.801 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.2328\n",
      "2017-05-06 23:17:06.931097: step 2200, loss = 1.26 (314.8 examples/sec; 0.813 sec/batch)\n",
      "2017-05-06 23:17:14.984568: step 2210, loss = 1.27 (317.9 examples/sec; 0.805 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 2215 into /tmp/cifar10_train_network1/model.ckpt.\n",
      "2017-05-06 23:17:24.726012: step 2220, loss = 1.25 (262.8 examples/sec; 0.974 sec/batch)\n",
      "2017-05-06 23:17:32.892415: step 2230, loss = 1.25 (313.5 examples/sec; 0.817 sec/batch)\n",
      "2017-05-06 23:17:41.151594: step 2240, loss = 1.32 (310.0 examples/sec; 0.826 sec/batch)\n",
      "2017-05-06 23:17:49.286057: step 2250, loss = 1.37 (314.7 examples/sec; 0.813 sec/batch)\n",
      "2017-05-06 23:17:57.361622: step 2260, loss = 1.20 (317.0 examples/sec; 0.808 sec/batch)\n",
      "2017-05-06 23:18:05.493695: step 2270, loss = 1.36 (314.8 examples/sec; 0.813 sec/batch)\n",
      "2017-05-06 23:18:13.672489: step 2280, loss = 1.22 (313.0 examples/sec; 0.818 sec/batch)\n",
      "2017-05-06 23:18:21.118984: step 2290, loss = 1.44 (343.8 examples/sec; 0.745 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.21209\n",
      "2017-05-06 23:18:29.437716: step 2300, loss = 1.45 (307.7 examples/sec; 0.832 sec/batch)\n",
      "2017-05-06 23:18:37.579954: step 2310, loss = 1.15 (314.4 examples/sec; 0.814 sec/batch)\n",
      "2017-05-06 23:18:45.900869: step 2320, loss = 1.28 (307.7 examples/sec; 0.832 sec/batch)\n",
      "2017-05-06 23:18:54.061597: step 2330, loss = 1.35 (313.7 examples/sec; 0.816 sec/batch)\n",
      "2017-05-06 23:19:02.423264: step 2340, loss = 1.33 (306.2 examples/sec; 0.836 sec/batch)\n",
      "2017-05-06 23:19:12.387146: step 2350, loss = 1.39 (256.9 examples/sec; 0.996 sec/batch)\n",
      "2017-05-06 23:19:23.315690: step 2360, loss = 1.29 (234.2 examples/sec; 1.093 sec/batch)\n",
      "2017-05-06 23:19:32.917123: step 2370, loss = 1.24 (266.6 examples/sec; 0.960 sec/batch)\n",
      "2017-05-06 23:19:41.538111: step 2380, loss = 1.17 (296.9 examples/sec; 0.862 sec/batch)\n",
      "2017-05-06 23:19:49.898280: step 2390, loss = 1.29 (306.2 examples/sec; 0.836 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12222\n",
      "2017-05-06 23:19:58.543380: step 2400, loss = 1.20 (296.1 examples/sec; 0.865 sec/batch)\n",
      "2017-05-06 23:20:06.993969: step 2410, loss = 1.09 (302.9 examples/sec; 0.845 sec/batch)\n",
      "2017-05-06 23:20:15.437398: step 2420, loss = 1.29 (303.2 examples/sec; 0.844 sec/batch)\n",
      "2017-05-06 23:20:23.677388: step 2430, loss = 1.27 (310.7 examples/sec; 0.824 sec/batch)\n",
      "2017-05-06 23:20:31.771456: step 2440, loss = 1.28 (316.3 examples/sec; 0.809 sec/batch)\n",
      "2017-05-06 23:20:40.004771: step 2450, loss = 1.29 (310.9 examples/sec; 0.823 sec/batch)\n",
      "2017-05-06 23:20:48.161521: step 2460, loss = 1.33 (313.9 examples/sec; 0.816 sec/batch)\n",
      "2017-05-06 23:20:56.260573: step 2470, loss = 1.28 (316.1 examples/sec; 0.810 sec/batch)\n",
      "2017-05-06 23:21:04.478039: step 2480, loss = 1.17 (311.5 examples/sec; 0.822 sec/batch)\n",
      "2017-05-06 23:21:12.586186: step 2490, loss = 1.14 (315.7 examples/sec; 0.811 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.2157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-06 23:21:20.803295: step 2500, loss = 1.20 (311.5 examples/sec; 0.822 sec/batch)\n",
      "2017-05-06 23:21:29.024800: step 2510, loss = 1.21 (311.4 examples/sec; 0.822 sec/batch)\n",
      "2017-05-06 23:21:37.256697: step 2520, loss = 1.41 (311.0 examples/sec; 0.823 sec/batch)\n",
      "2017-05-06 23:21:45.418540: step 2530, loss = 1.25 (313.7 examples/sec; 0.816 sec/batch)\n",
      "2017-05-06 23:21:53.543454: step 2540, loss = 1.25 (315.1 examples/sec; 0.812 sec/batch)\n",
      "2017-05-06 23:22:01.628277: step 2550, loss = 1.20 (316.6 examples/sec; 0.808 sec/batch)\n",
      "2017-05-06 23:22:09.812331: step 2560, loss = 1.21 (312.8 examples/sec; 0.818 sec/batch)\n",
      "2017-05-06 23:22:17.964473: step 2570, loss = 1.18 (314.0 examples/sec; 0.815 sec/batch)\n",
      "2017-05-06 23:22:26.010791: step 2580, loss = 1.53 (318.2 examples/sec; 0.805 sec/batch)\n",
      "2017-05-06 23:22:34.132607: step 2590, loss = 1.30 (315.2 examples/sec; 0.812 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.2239\n",
      "2017-05-06 23:22:42.500828: step 2600, loss = 1.19 (305.9 examples/sec; 0.837 sec/batch)\n",
      "2017-05-06 23:22:50.581075: step 2610, loss = 1.10 (316.8 examples/sec; 0.808 sec/batch)\n",
      "2017-05-06 23:22:58.704191: step 2620, loss = 1.30 (315.2 examples/sec; 0.812 sec/batch)\n",
      "2017-05-06 23:23:06.930263: step 2630, loss = 1.35 (311.2 examples/sec; 0.823 sec/batch)\n",
      "2017-05-06 23:23:15.008213: step 2640, loss = 1.32 (316.9 examples/sec; 0.808 sec/batch)\n",
      "2017-05-06 23:23:25.039168: step 2650, loss = 1.30 (255.2 examples/sec; 1.003 sec/batch)\n",
      "2017-05-06 23:23:34.521479: step 2660, loss = 1.20 (270.0 examples/sec; 0.948 sec/batch)\n",
      "2017-05-06 23:23:44.538863: step 2670, loss = 1.33 (255.6 examples/sec; 1.002 sec/batch)\n",
      "2017-05-06 23:23:53.366723: step 2680, loss = 1.19 (290.0 examples/sec; 0.883 sec/batch)\n",
      "2017-05-06 23:24:01.777443: step 2690, loss = 1.28 (304.4 examples/sec; 0.841 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.13207\n",
      "2017-05-06 23:24:10.840559: step 2700, loss = 1.20 (282.5 examples/sec; 0.906 sec/batch)\n",
      "2017-05-06 23:24:19.835967: step 2710, loss = 1.25 (284.6 examples/sec; 0.900 sec/batch)\n",
      "2017-05-06 23:24:27.933233: step 2720, loss = 1.33 (316.2 examples/sec; 0.810 sec/batch)\n",
      "2017-05-06 23:24:36.013501: step 2730, loss = 1.23 (316.8 examples/sec; 0.808 sec/batch)\n",
      "2017-05-06 23:24:44.927812: step 2740, loss = 1.24 (287.2 examples/sec; 0.891 sec/batch)\n",
      "2017-05-06 23:24:53.300710: step 2750, loss = 1.33 (305.7 examples/sec; 0.837 sec/batch)\n",
      "2017-05-06 23:25:01.437921: step 2760, loss = 1.15 (314.6 examples/sec; 0.814 sec/batch)\n",
      "2017-05-06 23:25:09.527000: step 2770, loss = 1.26 (316.5 examples/sec; 0.809 sec/batch)\n",
      "2017-05-06 23:25:17.733876: step 2780, loss = 1.18 (311.9 examples/sec; 0.821 sec/batch)\n",
      "2017-05-06 23:25:25.879617: step 2790, loss = 1.19 (314.3 examples/sec; 0.815 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.19952\n",
      "2017-05-06 23:25:34.206162: step 2800, loss = 1.08 (307.5 examples/sec; 0.833 sec/batch)\n",
      "2017-05-06 23:25:42.342407: step 2810, loss = 1.19 (314.6 examples/sec; 0.814 sec/batch)\n",
      "2017-05-06 23:25:50.871947: step 2820, loss = 0.94 (300.1 examples/sec; 0.853 sec/batch)\n",
      "2017-05-06 23:25:59.672573: step 2830, loss = 1.13 (290.9 examples/sec; 0.880 sec/batch)\n",
      "2017-05-06 23:26:09.202836: step 2840, loss = 1.16 (268.6 examples/sec; 0.953 sec/batch)\n",
      "2017-05-06 23:26:17.415438: step 2850, loss = 1.31 (311.7 examples/sec; 0.821 sec/batch)\n",
      "2017-05-06 23:26:26.193399: step 2860, loss = 1.22 (291.6 examples/sec; 0.878 sec/batch)\n",
      "2017-05-06 23:26:34.712165: step 2870, loss = 1.04 (300.5 examples/sec; 0.852 sec/batch)\n",
      "2017-05-06 23:26:43.497609: step 2880, loss = 1.23 (291.4 examples/sec; 0.879 sec/batch)\n",
      "2017-05-06 23:26:51.656567: step 2890, loss = 1.26 (313.8 examples/sec; 0.816 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.16569\n",
      "2017-05-06 23:26:59.989452: step 2900, loss = 1.10 (307.2 examples/sec; 0.833 sec/batch)\n",
      "2017-05-06 23:27:08.217792: step 2910, loss = 1.28 (311.1 examples/sec; 0.823 sec/batch)\n",
      "2017-05-06 23:27:16.384981: step 2920, loss = 1.06 (313.4 examples/sec; 0.817 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 2924 into /tmp/cifar10_train_network1/model.ckpt.\n",
      "2017-05-06 23:27:26.062102: step 2930, loss = 1.16 (264.5 examples/sec; 0.968 sec/batch)\n",
      "2017-05-06 23:27:34.733842: step 2940, loss = 1.25 (295.2 examples/sec; 0.867 sec/batch)\n",
      "2017-05-06 23:27:43.655281: step 2950, loss = 1.15 (286.9 examples/sec; 0.892 sec/batch)\n",
      "2017-05-06 23:27:53.635797: step 2960, loss = 1.44 (256.5 examples/sec; 0.998 sec/batch)\n",
      "2017-05-06 23:28:03.195400: step 2970, loss = 1.17 (267.8 examples/sec; 0.956 sec/batch)\n",
      "2017-05-06 23:28:12.613581: step 2980, loss = 1.24 (271.8 examples/sec; 0.942 sec/batch)\n",
      "2017-05-06 23:28:20.394412: step 2990, loss = 1.17 (329.0 examples/sec; 0.778 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.12308\n",
      "2017-05-06 23:28:29.031181: step 3000, loss = 1.17 (296.4 examples/sec; 0.864 sec/batch)\n",
      "2017-05-06 23:28:37.121391: step 3010, loss = 1.18 (316.4 examples/sec; 0.809 sec/batch)\n",
      "2017-05-06 23:28:45.976250: step 3020, loss = 1.09 (289.1 examples/sec; 0.885 sec/batch)\n",
      "2017-05-06 23:28:55.070957: step 3030, loss = 1.18 (281.5 examples/sec; 0.909 sec/batch)\n",
      "2017-05-06 23:29:03.623340: step 3040, loss = 1.20 (299.3 examples/sec; 0.855 sec/batch)\n",
      "2017-05-06 23:29:12.196219: step 3050, loss = 1.18 (298.6 examples/sec; 0.857 sec/batch)\n",
      "2017-05-06 23:29:20.929270: step 3060, loss = 1.14 (293.1 examples/sec; 0.873 sec/batch)\n",
      "2017-05-06 23:29:29.215972: step 3070, loss = 1.26 (308.9 examples/sec; 0.829 sec/batch)\n",
      "2017-05-06 23:29:37.830821: step 3080, loss = 1.19 (297.2 examples/sec; 0.861 sec/batch)\n",
      "2017-05-06 23:29:46.147410: step 3090, loss = 1.12 (307.8 examples/sec; 0.832 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.17015\n",
      "2017-05-06 23:29:54.488892: step 3100, loss = 1.08 (306.9 examples/sec; 0.834 sec/batch)\n",
      "2017-05-06 23:30:02.707285: step 3110, loss = 1.07 (311.5 examples/sec; 0.822 sec/batch)\n",
      "2017-05-06 23:30:10.982222: step 3120, loss = 1.16 (309.4 examples/sec; 0.827 sec/batch)\n",
      "2017-05-06 23:30:19.171293: step 3130, loss = 1.26 (312.6 examples/sec; 0.819 sec/batch)\n",
      "2017-05-06 23:30:27.353802: step 3140, loss = 1.19 (312.9 examples/sec; 0.818 sec/batch)\n",
      "2017-05-06 23:30:35.472263: step 3150, loss = 1.15 (315.3 examples/sec; 0.812 sec/batch)\n",
      "2017-05-06 23:30:43.644682: step 3160, loss = 1.40 (313.2 examples/sec; 0.817 sec/batch)\n",
      "2017-05-06 23:30:51.904419: step 3170, loss = 1.20 (309.9 examples/sec; 0.826 sec/batch)\n",
      "2017-05-06 23:31:00.148290: step 3180, loss = 1.13 (310.5 examples/sec; 0.824 sec/batch)\n",
      "2017-05-06 23:31:08.737345: step 3190, loss = 1.19 (298.1 examples/sec; 0.859 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.18816\n",
      "2017-05-06 23:31:18.652055: step 3200, loss = 1.10 (258.2 examples/sec; 0.991 sec/batch)\n",
      "2017-05-06 23:31:27.075929: step 3210, loss = 1.17 (303.9 examples/sec; 0.842 sec/batch)\n",
      "2017-05-06 23:31:35.383070: step 3220, loss = 1.16 (308.2 examples/sec; 0.831 sec/batch)\n",
      "2017-05-06 23:31:43.627731: step 3230, loss = 1.23 (310.5 examples/sec; 0.824 sec/batch)\n",
      "2017-05-06 23:31:51.568887: step 3240, loss = 1.27 (322.4 examples/sec; 0.794 sec/batch)\n",
      "2017-05-06 23:31:59.714092: step 3250, loss = 1.15 (314.3 examples/sec; 0.815 sec/batch)\n",
      "2017-05-06 23:32:07.666135: step 3260, loss = 1.21 (321.9 examples/sec; 0.795 sec/batch)\n",
      "2017-05-06 23:32:15.837318: step 3270, loss = 1.16 (313.3 examples/sec; 0.817 sec/batch)\n",
      "2017-05-06 23:32:23.862807: step 3280, loss = 1.19 (319.0 examples/sec; 0.803 sec/batch)\n",
      "2017-05-06 23:32:31.861626: step 3290, loss = 1.31 (320.0 examples/sec; 0.800 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.22937\n",
      "2017-05-06 23:32:39.994140: step 3300, loss = 1.18 (314.8 examples/sec; 0.813 sec/batch)\n",
      "2017-05-06 23:32:48.102438: step 3310, loss = 1.12 (315.7 examples/sec; 0.811 sec/batch)\n",
      "2017-05-06 23:32:56.201903: step 3320, loss = 1.27 (316.1 examples/sec; 0.810 sec/batch)\n",
      "2017-05-06 23:33:04.284102: step 3330, loss = 1.13 (316.7 examples/sec; 0.808 sec/batch)\n",
      "2017-05-06 23:33:12.502172: step 3340, loss = 1.13 (311.5 examples/sec; 0.822 sec/batch)\n",
      "2017-05-06 23:33:20.661048: step 3350, loss = 1.20 (313.8 examples/sec; 0.816 sec/batch)\n",
      "2017-05-06 23:33:28.775401: step 3360, loss = 1.44 (315.5 examples/sec; 0.811 sec/batch)\n",
      "2017-05-06 23:33:36.871704: step 3370, loss = 1.21 (316.2 examples/sec; 0.810 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-06 23:33:45.100691: step 3380, loss = 1.22 (311.1 examples/sec; 0.823 sec/batch)\n",
      "2017-05-06 23:33:53.121831: step 3390, loss = 1.16 (319.2 examples/sec; 0.802 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.2299\n",
      "2017-05-06 23:34:01.313646: step 3400, loss = 1.17 (312.5 examples/sec; 0.819 sec/batch)\n",
      "2017-05-06 23:34:09.381942: step 3410, loss = 1.19 (317.3 examples/sec; 0.807 sec/batch)\n",
      "2017-05-06 23:34:17.477007: step 3420, loss = 1.07 (316.2 examples/sec; 0.810 sec/batch)\n",
      "2017-05-06 23:34:25.594624: step 3430, loss = 1.21 (315.4 examples/sec; 0.812 sec/batch)\n",
      "2017-05-06 23:34:33.669161: step 3440, loss = 1.27 (317.0 examples/sec; 0.807 sec/batch)\n",
      "2017-05-06 23:34:41.801553: step 3450, loss = 1.10 (314.8 examples/sec; 0.813 sec/batch)\n",
      "2017-05-06 23:34:49.987085: step 3460, loss = 1.25 (312.7 examples/sec; 0.819 sec/batch)\n",
      "2017-05-06 23:34:58.081232: step 3470, loss = 1.18 (316.3 examples/sec; 0.809 sec/batch)\n",
      "2017-05-06 23:35:06.148469: step 3480, loss = 1.11 (317.3 examples/sec; 0.807 sec/batch)\n",
      "2017-05-06 23:35:14.242708: step 3490, loss = 1.11 (316.3 examples/sec; 0.809 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.23242\n",
      "2017-05-06 23:35:22.443829: step 3500, loss = 1.16 (312.2 examples/sec; 0.820 sec/batch)\n",
      "2017-05-06 23:35:30.564169: step 3510, loss = 1.03 (315.3 examples/sec; 0.812 sec/batch)\n",
      "2017-05-06 23:35:38.677780: step 3520, loss = 1.23 (315.5 examples/sec; 0.811 sec/batch)\n",
      "2017-05-06 23:35:46.716575: step 3530, loss = 1.07 (318.5 examples/sec; 0.804 sec/batch)\n",
      "2017-05-06 23:35:54.868183: step 3540, loss = 1.07 (314.0 examples/sec; 0.815 sec/batch)\n",
      "2017-05-06 23:36:02.981929: step 3550, loss = 1.01 (315.5 examples/sec; 0.811 sec/batch)\n",
      "2017-05-06 23:36:10.971267: step 3560, loss = 1.14 (320.4 examples/sec; 0.799 sec/batch)\n",
      "2017-05-06 23:36:19.036635: step 3570, loss = 1.13 (317.4 examples/sec; 0.807 sec/batch)\n",
      "2017-05-06 23:36:27.213218: step 3580, loss = 1.15 (313.1 examples/sec; 0.818 sec/batch)\n",
      "2017-05-06 23:36:35.350823: step 3590, loss = 1.08 (314.6 examples/sec; 0.814 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.23425\n",
      "2017-05-06 23:36:43.471393: step 3600, loss = 0.99 (315.2 examples/sec; 0.812 sec/batch)\n",
      "2017-05-06 23:36:51.650936: step 3610, loss = 1.31 (313.0 examples/sec; 0.818 sec/batch)\n",
      "2017-05-06 23:36:59.712422: step 3620, loss = 1.09 (317.6 examples/sec; 0.806 sec/batch)\n",
      "2017-05-06 23:37:07.822549: step 3630, loss = 1.17 (315.7 examples/sec; 0.811 sec/batch)\n",
      "2017-05-06 23:37:16.025270: step 3640, loss = 1.13 (312.1 examples/sec; 0.820 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 3645 into /tmp/cifar10_train_network1/model.ckpt.\n",
      "2017-05-06 23:37:25.544595: step 3650, loss = 1.21 (268.9 examples/sec; 0.952 sec/batch)\n",
      "2017-05-06 23:37:33.617507: step 3660, loss = 1.24 (317.1 examples/sec; 0.807 sec/batch)\n",
      "2017-05-06 23:37:41.819258: step 3670, loss = 1.12 (312.1 examples/sec; 0.820 sec/batch)\n",
      "2017-05-06 23:37:49.976071: step 3680, loss = 1.10 (313.8 examples/sec; 0.816 sec/batch)\n",
      "2017-05-06 23:37:58.002757: step 3690, loss = 1.02 (318.9 examples/sec; 0.803 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.20709\n",
      "2017-05-06 23:38:06.307450: step 3700, loss = 1.14 (308.3 examples/sec; 0.830 sec/batch)\n",
      "2017-05-06 23:38:14.417813: step 3710, loss = 1.11 (315.6 examples/sec; 0.811 sec/batch)\n",
      "2017-05-06 23:38:21.917539: step 3720, loss = 1.14 (341.3 examples/sec; 0.750 sec/batch)\n",
      "2017-05-06 23:38:29.978986: step 3730, loss = 1.17 (317.6 examples/sec; 0.806 sec/batch)\n",
      "2017-05-06 23:38:38.252908: step 3740, loss = 1.19 (309.4 examples/sec; 0.827 sec/batch)\n",
      "2017-05-06 23:38:46.459915: step 3750, loss = 1.11 (311.9 examples/sec; 0.821 sec/batch)\n",
      "2017-05-06 23:38:54.541069: step 3760, loss = 1.16 (316.8 examples/sec; 0.808 sec/batch)\n",
      "2017-05-06 23:39:02.676087: step 3770, loss = 1.13 (314.7 examples/sec; 0.814 sec/batch)\n",
      "2017-05-06 23:39:12.946623: step 3780, loss = 1.08 (249.3 examples/sec; 1.027 sec/batch)\n",
      "2017-05-06 23:39:22.224654: step 3790, loss = 1.08 (275.9 examples/sec; 0.928 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.16929\n",
      "2017-05-06 23:39:31.829649: step 3800, loss = 1.25 (266.5 examples/sec; 0.960 sec/batch)\n",
      "2017-05-06 23:39:40.769160: step 3810, loss = 1.14 (286.4 examples/sec; 0.894 sec/batch)\n",
      "2017-05-06 23:39:49.161965: step 3820, loss = 1.32 (305.0 examples/sec; 0.839 sec/batch)\n",
      "2017-05-06 23:39:57.239249: step 3830, loss = 1.09 (316.9 examples/sec; 0.808 sec/batch)\n",
      "2017-05-06 23:40:05.285223: step 3840, loss = 1.06 (318.2 examples/sec; 0.805 sec/batch)\n",
      "2017-05-06 23:40:13.413073: step 3850, loss = 1.17 (315.0 examples/sec; 0.813 sec/batch)\n",
      "2017-05-06 23:40:21.619903: step 3860, loss = 1.15 (311.9 examples/sec; 0.821 sec/batch)\n",
      "2017-05-06 23:40:29.648077: step 3870, loss = 1.04 (318.9 examples/sec; 0.803 sec/batch)\n",
      "2017-05-06 23:40:37.711043: step 3880, loss = 1.32 (317.5 examples/sec; 0.806 sec/batch)\n",
      "2017-05-06 23:40:45.786964: step 3890, loss = 1.23 (317.0 examples/sec; 0.808 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.21795\n",
      "2017-05-06 23:40:53.939673: step 3900, loss = 1.02 (314.0 examples/sec; 0.815 sec/batch)\n",
      "2017-05-06 23:41:02.088508: step 3910, loss = 1.32 (314.2 examples/sec; 0.815 sec/batch)\n",
      "2017-05-06 23:41:10.271004: step 3920, loss = 1.14 (312.9 examples/sec; 0.818 sec/batch)\n",
      "2017-05-06 23:41:18.442964: step 3930, loss = 1.13 (313.3 examples/sec; 0.817 sec/batch)\n",
      "2017-05-06 23:41:26.537267: step 3940, loss = 1.28 (316.3 examples/sec; 0.809 sec/batch)\n",
      "2017-05-06 23:41:34.654369: step 3950, loss = 1.15 (315.4 examples/sec; 0.812 sec/batch)\n",
      "2017-05-06 23:41:42.845967: step 3960, loss = 1.15 (312.5 examples/sec; 0.819 sec/batch)\n",
      "2017-05-06 23:41:51.039047: step 3970, loss = 1.03 (312.5 examples/sec; 0.819 sec/batch)\n",
      "2017-05-06 23:41:59.225000: step 3980, loss = 1.12 (312.7 examples/sec; 0.819 sec/batch)\n",
      "2017-05-06 23:42:07.345211: step 3990, loss = 1.09 (315.3 examples/sec; 0.812 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.22532\n",
      "2017-05-06 23:42:15.565616: step 4000, loss = 1.13 (311.4 examples/sec; 0.822 sec/batch)\n",
      "2017-05-06 23:42:23.661787: step 4010, loss = 1.17 (316.2 examples/sec; 0.810 sec/batch)\n",
      "2017-05-06 23:42:31.909205: step 4020, loss = 1.07 (310.4 examples/sec; 0.825 sec/batch)\n",
      "2017-05-06 23:42:39.970836: step 4030, loss = 1.13 (317.6 examples/sec; 0.806 sec/batch)\n",
      "2017-05-06 23:42:49.642001: step 4040, loss = 1.19 (264.7 examples/sec; 0.967 sec/batch)\n",
      "2017-05-06 23:42:59.339420: step 4050, loss = 1.05 (264.0 examples/sec; 0.970 sec/batch)\n",
      "2017-05-06 23:43:07.963354: step 4060, loss = 1.07 (296.8 examples/sec; 0.862 sec/batch)\n",
      "2017-05-06 23:43:17.737426: step 4070, loss = 1.22 (261.9 examples/sec; 0.977 sec/batch)\n",
      "2017-05-06 23:43:25.910916: step 4080, loss = 0.96 (313.2 examples/sec; 0.817 sec/batch)\n",
      "2017-05-06 23:43:33.887473: step 4090, loss = 1.14 (320.9 examples/sec; 0.798 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.15387\n",
      "2017-05-06 23:43:42.218720: step 4100, loss = 1.27 (307.3 examples/sec; 0.833 sec/batch)\n",
      "2017-05-06 23:43:50.412504: step 4110, loss = 1.11 (312.4 examples/sec; 0.819 sec/batch)\n",
      "2017-05-06 23:43:58.433551: step 4120, loss = 1.14 (319.2 examples/sec; 0.802 sec/batch)\n",
      "2017-05-06 23:44:06.518614: step 4130, loss = 1.06 (316.6 examples/sec; 0.809 sec/batch)\n",
      "2017-05-06 23:44:14.587010: step 4140, loss = 1.15 (317.3 examples/sec; 0.807 sec/batch)\n",
      "2017-05-06 23:44:22.647067: step 4150, loss = 1.16 (317.6 examples/sec; 0.806 sec/batch)\n",
      "2017-05-06 23:44:30.785945: step 4160, loss = 1.08 (314.5 examples/sec; 0.814 sec/batch)\n",
      "2017-05-06 23:44:40.233066: step 4170, loss = 1.14 (271.0 examples/sec; 0.945 sec/batch)\n",
      "2017-05-06 23:44:48.320087: step 4180, loss = 1.06 (316.6 examples/sec; 0.809 sec/batch)\n",
      "2017-05-06 23:44:56.315561: step 4190, loss = 1.20 (320.2 examples/sec; 0.800 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.2137\n",
      "2017-05-06 23:45:04.600794: step 4200, loss = 1.03 (309.0 examples/sec; 0.829 sec/batch)\n",
      "2017-05-06 23:45:12.671274: step 4210, loss = 1.10 (317.2 examples/sec; 0.807 sec/batch)\n",
      "2017-05-06 23:45:20.768169: step 4220, loss = 1.16 (316.2 examples/sec; 0.810 sec/batch)\n",
      "2017-05-06 23:45:28.855778: step 4230, loss = 1.03 (316.5 examples/sec; 0.809 sec/batch)\n",
      "2017-05-06 23:45:36.889532: step 4240, loss = 1.09 (318.7 examples/sec; 0.803 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-06 23:45:45.061448: step 4250, loss = 1.05 (313.3 examples/sec; 0.817 sec/batch)\n",
      "2017-05-06 23:45:53.186002: step 4260, loss = 1.16 (315.1 examples/sec; 0.812 sec/batch)\n",
      "2017-05-06 23:46:01.280772: step 4270, loss = 0.99 (316.3 examples/sec; 0.809 sec/batch)\n",
      "2017-05-06 23:46:09.437028: step 4280, loss = 1.11 (313.9 examples/sec; 0.816 sec/batch)\n",
      "2017-05-06 23:46:17.543908: step 4290, loss = 1.26 (315.8 examples/sec; 0.811 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.2343\n",
      "2017-05-06 23:46:25.625262: step 4300, loss = 1.04 (316.8 examples/sec; 0.808 sec/batch)\n",
      "2017-05-06 23:46:33.672346: step 4310, loss = 1.18 (318.1 examples/sec; 0.805 sec/batch)\n",
      "2017-05-06 23:46:41.694641: step 4320, loss = 1.32 (319.1 examples/sec; 0.802 sec/batch)\n",
      "2017-05-06 23:46:49.798928: step 4330, loss = 1.13 (315.9 examples/sec; 0.810 sec/batch)\n",
      "2017-05-06 23:46:57.867539: step 4340, loss = 1.15 (317.3 examples/sec; 0.807 sec/batch)\n",
      "2017-05-06 23:47:05.899935: step 4350, loss = 1.18 (318.7 examples/sec; 0.803 sec/batch)\n",
      "2017-05-06 23:47:14.000073: step 4360, loss = 1.07 (316.0 examples/sec; 0.810 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 4368 into /tmp/cifar10_train_network1/model.ckpt.\n",
      "2017-05-06 23:47:23.746477: step 4370, loss = 0.99 (262.7 examples/sec; 0.975 sec/batch)\n",
      "2017-05-06 23:47:31.821610: step 4380, loss = 1.14 (317.0 examples/sec; 0.808 sec/batch)\n",
      "2017-05-06 23:47:39.942927: step 4390, loss = 1.02 (315.2 examples/sec; 0.812 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.21071\n",
      "2017-05-06 23:47:48.217489: step 4400, loss = 1.06 (309.4 examples/sec; 0.827 sec/batch)\n",
      "2017-05-06 23:47:56.393302: step 4410, loss = 1.14 (313.1 examples/sec; 0.818 sec/batch)\n",
      "2017-05-06 23:48:04.558305: step 4420, loss = 1.05 (313.5 examples/sec; 0.817 sec/batch)\n",
      "2017-05-06 23:48:12.638146: step 4430, loss = 1.05 (316.8 examples/sec; 0.808 sec/batch)\n",
      "2017-05-06 23:48:20.096996: step 4440, loss = 1.19 (343.2 examples/sec; 0.746 sec/batch)\n",
      "2017-05-06 23:48:28.201764: step 4450, loss = 1.10 (315.9 examples/sec; 0.810 sec/batch)\n",
      "2017-05-06 23:48:36.278857: step 4460, loss = 1.08 (316.9 examples/sec; 0.808 sec/batch)\n",
      "2017-05-06 23:48:45.743996: step 4470, loss = 1.21 (270.5 examples/sec; 0.947 sec/batch)\n",
      "2017-05-06 23:48:55.419529: step 4480, loss = 1.22 (264.6 examples/sec; 0.968 sec/batch)\n",
      "2017-05-06 23:49:07.147886: step 4490, loss = 1.06 (218.3 examples/sec; 1.173 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.08074\n",
      "2017-05-06 23:49:20.747947: step 4500, loss = 1.01 (188.2 examples/sec; 1.360 sec/batch)\n",
      "2017-05-06 23:49:35.526699: step 4510, loss = 1.16 (173.2 examples/sec; 1.478 sec/batch)\n",
      "2017-05-06 23:49:53.096472: step 4520, loss = 1.11 (145.7 examples/sec; 1.757 sec/batch)\n",
      "2017-05-06 23:50:05.634221: step 4530, loss = 1.00 (204.2 examples/sec; 1.254 sec/batch)\n",
      "2017-05-06 23:50:18.909119: step 4540, loss = 1.02 (192.8 examples/sec; 1.327 sec/batch)\n",
      "2017-05-06 23:50:31.723796: step 4550, loss = 1.16 (199.8 examples/sec; 1.281 sec/batch)\n",
      "2017-05-06 23:50:40.631632: step 4560, loss = 1.31 (287.4 examples/sec; 0.891 sec/batch)\n",
      "2017-05-06 23:50:52.269927: step 4570, loss = 1.03 (220.0 examples/sec; 1.164 sec/batch)\n",
      "2017-05-06 23:51:00.774824: step 4580, loss = 1.15 (301.0 examples/sec; 0.850 sec/batch)\n",
      "2017-05-06 23:51:09.838217: step 4590, loss = 1.01 (282.5 examples/sec; 0.906 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.844651\n",
      "2017-05-06 23:51:19.142520: step 4600, loss = 1.19 (275.1 examples/sec; 0.930 sec/batch)\n",
      "2017-05-06 23:51:29.090191: step 4610, loss = 1.26 (257.3 examples/sec; 0.995 sec/batch)\n",
      "2017-05-06 23:51:38.174873: step 4620, loss = 1.07 (281.8 examples/sec; 0.908 sec/batch)\n",
      "2017-05-06 23:51:47.642009: step 4630, loss = 1.17 (270.4 examples/sec; 0.947 sec/batch)\n",
      "2017-05-06 23:51:57.843960: step 4640, loss = 1.19 (250.9 examples/sec; 1.020 sec/batch)\n",
      "2017-05-06 23:52:06.443701: step 4650, loss = 1.04 (297.7 examples/sec; 0.860 sec/batch)\n",
      "2017-05-06 23:52:15.273683: step 4660, loss = 1.02 (289.9 examples/sec; 0.883 sec/batch)\n",
      "2017-05-06 23:52:25.105333: step 4670, loss = 1.08 (260.4 examples/sec; 0.983 sec/batch)\n",
      "2017-05-06 23:52:34.418469: step 4680, loss = 0.96 (274.9 examples/sec; 0.931 sec/batch)\n",
      "2017-05-06 23:52:43.889941: step 4690, loss = 1.09 (270.3 examples/sec; 0.947 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.0384\n",
      "2017-05-06 23:52:55.445650: step 4700, loss = 1.10 (221.5 examples/sec; 1.156 sec/batch)\n",
      "2017-05-06 23:53:09.476966: step 4710, loss = 1.06 (182.4 examples/sec; 1.403 sec/batch)\n",
      "2017-05-06 23:53:20.686046: step 4720, loss = 1.03 (228.4 examples/sec; 1.121 sec/batch)\n",
      "2017-05-06 23:53:34.659124: step 4730, loss = 1.06 (183.2 examples/sec; 1.397 sec/batch)\n",
      "2017-05-06 23:53:45.311600: step 4740, loss = 1.01 (240.3 examples/sec; 1.065 sec/batch)\n",
      "2017-05-06 23:53:58.629409: step 4750, loss = 1.01 (192.2 examples/sec; 1.332 sec/batch)\n",
      "2017-05-06 23:54:07.260275: step 4760, loss = 1.05 (296.6 examples/sec; 0.863 sec/batch)\n",
      "2017-05-06 23:54:15.464662: step 4770, loss = 1.12 (312.0 examples/sec; 0.820 sec/batch)\n",
      "2017-05-06 23:54:23.752726: step 4780, loss = 1.29 (308.9 examples/sec; 0.829 sec/batch)\n",
      "2017-05-06 23:54:31.914598: step 4790, loss = 1.33 (313.7 examples/sec; 0.816 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 0.955238\n",
      "2017-05-06 23:54:40.127522: step 4800, loss = 1.09 (311.7 examples/sec; 0.821 sec/batch)\n",
      "2017-05-06 23:54:49.888523: step 4810, loss = 1.03 (262.3 examples/sec; 0.976 sec/batch)\n",
      "2017-05-06 23:54:59.254970: step 4820, loss = 1.04 (273.3 examples/sec; 0.937 sec/batch)\n",
      "2017-05-06 23:55:08.028687: step 4830, loss = 1.04 (291.8 examples/sec; 0.877 sec/batch)\n",
      "2017-05-06 23:55:16.668058: step 4840, loss = 1.21 (296.3 examples/sec; 0.864 sec/batch)\n",
      "2017-05-06 23:55:25.289596: step 4850, loss = 1.16 (296.9 examples/sec; 0.862 sec/batch)\n",
      "2017-05-06 23:55:33.752077: step 4860, loss = 1.00 (302.5 examples/sec; 0.846 sec/batch)\n",
      "2017-05-06 23:55:42.886180: step 4870, loss = 1.08 (280.3 examples/sec; 0.913 sec/batch)\n",
      "2017-05-06 23:55:48.514926: step 4880, loss = 1.10 (454.8 examples/sec; 0.563 sec/batch)\n",
      "2017-05-06 23:55:55.062830: step 4890, loss = 0.95 (391.0 examples/sec; 0.655 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.22659\n",
      "2017-05-06 23:56:01.649027: step 4900, loss = 1.15 (388.7 examples/sec; 0.659 sec/batch)\n",
      "2017-05-06 23:56:08.319348: step 4910, loss = 0.98 (383.8 examples/sec; 0.667 sec/batch)\n",
      "2017-05-06 23:56:18.323816: step 4920, loss = 1.09 (255.9 examples/sec; 1.000 sec/batch)\n",
      "2017-05-06 23:56:23.289118: step 4930, loss = 1.05 (515.6 examples/sec; 0.497 sec/batch)\n",
      "2017-05-06 23:56:33.063875: step 4940, loss = 1.00 (261.9 examples/sec; 0.977 sec/batch)\n",
      "2017-05-06 23:56:39.143973: step 4950, loss = 1.06 (421.0 examples/sec; 0.608 sec/batch)\n",
      "2017-05-06 23:56:47.865504: step 4960, loss = 1.00 (293.5 examples/sec; 0.872 sec/batch)\n",
      "2017-05-06 23:56:55.042861: step 4970, loss = 1.06 (356.7 examples/sec; 0.718 sec/batch)\n",
      "2017-05-06 23:57:02.568570: step 4980, loss = 0.90 (340.2 examples/sec; 0.753 sec/batch)\n",
      "2017-05-06 23:57:10.866537: step 4990, loss = 1.02 (308.5 examples/sec; 0.830 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.32277\n",
      "2017-05-06 23:57:17.254050: step 5000, loss = 1.13 (400.8 examples/sec; 0.639 sec/batch)\n",
      "INFO:tensorflow:Saving checkpoints for 5004 into /tmp/cifar10_train_network1/model.ckpt.\n",
      "2017-05-06 23:57:27.602496: step 5010, loss = 1.23 (247.4 examples/sec; 1.035 sec/batch)\n",
      "2017-05-06 23:57:34.571290: step 5020, loss = 1.02 (367.4 examples/sec; 0.697 sec/batch)\n",
      "2017-05-06 23:57:43.507137: step 5030, loss = 0.99 (286.5 examples/sec; 0.894 sec/batch)\n",
      "2017-05-06 23:57:49.433936: step 5040, loss = 1.11 (431.9 examples/sec; 0.593 sec/batch)\n",
      "2017-05-06 23:57:59.429925: step 5050, loss = 0.95 (256.1 examples/sec; 1.000 sec/batch)\n",
      "2017-05-06 23:58:04.472720: step 5060, loss = 1.07 (507.7 examples/sec; 0.504 sec/batch)\n",
      "2017-05-06 23:58:14.354279: step 5070, loss = 1.15 (259.1 examples/sec; 0.988 sec/batch)\n",
      "2017-05-06 23:58:20.314997: step 5080, loss = 1.17 (429.5 examples/sec; 0.596 sec/batch)\n",
      "2017-05-06 23:58:29.154110: step 5090, loss = 1.08 (289.6 examples/sec; 0.884 sec/batch)\n",
      "INFO:tensorflow:global_step/sec: 1.26528\n",
      "2017-05-06 23:58:36.270944: step 5100, loss = 1.11 (359.7 examples/sec; 0.712 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-06 23:58:44.315283: step 5110, loss = 0.97 (318.2 examples/sec; 0.804 sec/batch)\n",
      "2017-05-06 23:58:52.261397: step 5120, loss = 1.08 (322.2 examples/sec; 0.795 sec/batch)\n",
      "2017-05-06 23:58:58.965735: step 5130, loss = 0.94 (381.8 examples/sec; 0.670 sec/batch)\n",
      "2017-05-06 23:59:07.940794: step 5140, loss = 1.07 (285.2 examples/sec; 0.898 sec/batch)\n",
      "2017-05-06 23:59:13.830659: step 5150, loss = 1.08 (434.6 examples/sec; 0.589 sec/batch)\n",
      "2017-05-06 23:59:23.778663: step 5160, loss = 1.02 (257.3 examples/sec; 0.995 sec/batch)\n",
      "2017-05-06 23:59:28.844148: step 5170, loss = 0.96 (505.4 examples/sec; 0.507 sec/batch)\n",
      "2017-05-06 23:59:38.541598: step 5180, loss = 1.00 (264.0 examples/sec; 0.970 sec/batch)\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "eval_dir",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f3fa0288fa98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-3a42d53db4f2>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mcifar10_eval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mcifar10_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/sedanurdoganay/DeepLearning/CS-466-Project2/untitled folder/cifar10_eval.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=unused-argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m   \u001b[0mcifar10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_download_and_extract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDeleteRecursively\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMakeDirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sedanurdoganay/miniconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/platform/flags.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     48\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_flags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__flags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__flags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: eval_dir"
     ]
    }
   ],
   "source": [
    "evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
